2024-03-12 20:51:03,330 mega_core INFO: Using 1 GPUs
2024-03-12 20:51:03,330 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_visdrone.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-12 20:51:03,331 mega_core INFO: Collecting env info (might take some time)
2024-03-12 20:51:07,316 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] Could not collect
        Pillow (8.3.2)
2024-03-12 20:51:07,317 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_visdrone.yaml
2024-03-12 20:51:07,317 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_visdrone_train_2",)
  TEST: ("VID_visdrone_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-12 20:51:07,320 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_visdrone_val',)
  TRAIN: ('VID_visdrone_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-12 20:51:07,321 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-12 20:51:27,871 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-12 20:51:35,901 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-12 20:51:36,695 mega_core.trainer INFO: Start training
2024-03-13 20:56:18,361 mega_core INFO: Using 1 GPUs
2024-03-13 20:56:18,361 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 20:56:18,361 mega_core INFO: Collecting env info (might take some time)
2024-03-13 20:56:19,891 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 20:56:19,891 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 20:56:19,892 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 20:56:19,894 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 20:56:19,895 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 20:56:24,805 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:02:59,836 mega_core INFO: Using 1 GPUs
2024-03-13 21:02:59,836 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:02:59,837 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:03:01,320 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:03:01,321 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:03:01,321 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:03:01,323 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:03:01,324 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:03:06,156 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:18:45,374 mega_core INFO: Using 1 GPUs
2024-03-13 21:18:45,375 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:18:45,375 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:18:46,857 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:18:46,857 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:18:46,858 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:18:46,860 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:18:46,861 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:18:51,756 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:18:52,683 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 21:18:52,875 mega_core.trainer INFO: Start training
2024-03-13 21:19:38,639 mega_core INFO: Using 1 GPUs
2024-03-13 21:19:38,639 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:19:38,640 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:19:40,106 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:19:40,107 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:19:40,107 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:19:40,110 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:19:40,110 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:19:44,937 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:19:45,677 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 21:19:45,760 mega_core.trainer INFO: Start training
2024-03-13 21:44:32,039 mega_core INFO: Using 1 GPUs
2024-03-13 21:44:32,039 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:44:32,039 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:44:33,563 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:44:33,563 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:44:33,563 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:44:33,565 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:44:33,565 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:44:38,574 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:47:02,051 mega_core INFO: Using 1 GPUs
2024-03-13 21:47:02,051 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:47:02,051 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:47:03,583 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:47:03,583 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:47:03,584 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:47:03,586 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:47:03,587 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:47:08,676 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:50:32,867 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 21:53:15,599 mega_core INFO: Using 1 GPUs
2024-03-13 21:53:15,600 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:53:15,600 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:53:17,274 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:53:17,275 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:53:17,275 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:53:17,279 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:53:17,280 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:53:22,432 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:53:23,246 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 21:55:53,804 mega_core INFO: Using 1 GPUs
2024-03-13 21:55:53,804 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:55:53,804 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:55:55,532 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:55:55,533 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:55:55,533 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:55:55,536 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:55:55,537 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:56:00,758 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:57:16,073 mega_core INFO: Using 1 GPUs
2024-03-13 21:57:16,074 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:57:16,074 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:57:17,617 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:57:17,618 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:57:17,618 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:57:17,621 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:57:17,621 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:57:22,462 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:59:05,315 mega_core INFO: Using 1 GPUs
2024-03-13 21:59:05,315 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:59:05,315 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:59:06,909 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:59:06,910 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:59:06,910 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:59:06,913 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:59:06,913 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:59:11,738 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 21:59:46,415 mega_core INFO: Using 1 GPUs
2024-03-13 21:59:46,416 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 21:59:46,416 mega_core INFO: Collecting env info (might take some time)
2024-03-13 21:59:48,000 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 21:59:48,000 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 21:59:48,001 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 21:59:48,003 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 21:59:48,004 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 21:59:52,821 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:28:39,513 mega_core INFO: Using 1 GPUs
2024-03-13 22:28:39,514 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 22:28:39,514 mega_core INFO: Collecting env info (might take some time)
2024-03-13 22:28:41,068 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 22:28:41,069 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 22:28:41,069 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 22:28:41,072 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 22:28:41,073 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 22:28:45,964 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:32:06,317 mega_core INFO: Using 1 GPUs
2024-03-13 22:32:06,317 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 22:32:06,318 mega_core INFO: Collecting env info (might take some time)
2024-03-13 22:32:07,876 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 22:32:07,877 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 22:32:07,877 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 22:32:07,880 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 22:32:07,880 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 22:32:12,804 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:33:29,231 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 22:34:03,210 mega_core INFO: Using 1 GPUs
2024-03-13 22:34:03,210 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 22:34:03,211 mega_core INFO: Collecting env info (might take some time)
2024-03-13 22:34:04,743 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 22:34:04,744 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 22:34:04,744 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 22:34:04,747 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 22:34:04,747 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 22:34:09,541 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:36:07,122 mega_core INFO: Using 1 GPUs
2024-03-13 22:36:07,122 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 22:36:07,123 mega_core INFO: Collecting env info (might take some time)
2024-03-13 22:36:08,654 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 22:36:08,654 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 22:36:08,655 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 22:36:08,656 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 22:36:08,657 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 22:36:13,397 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:36:19,012 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 22:36:22,429 mega_core.trainer INFO: Start training
2024-03-13 22:56:20,717 mega_core INFO: Using 1 GPUs
2024-03-13 22:56:20,717 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_gaode_4.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-03-13 22:56:20,717 mega_core INFO: Collecting env info (might take some time)
2024-03-13 22:56:22,300 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: Could not collect
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-97-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-03-13 22:56:22,301 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_gaode_4.yaml
2024-03-13 22:56:22,301 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_gaode_4_train_2",)
  TEST: ("VID_gaode_4_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-03-13 22:56:22,304 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_gaode_4_val',)
  TRAIN: ('VID_gaode_4_train_2',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-03-13 22:56:22,304 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-03-13 22:56:27,205 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-03-13 22:56:43,220 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-03-13 22:56:46,600 mega_core.trainer INFO: Start training
2024-03-13 22:57:22,457 mega_core.trainer INFO: eta: 1 day, 8:21:15  iter: 21  loss: 15.0733 (17.2830)  loss_ce: 0.9263 (1.2228)  loss_bbox: 0.2130 (0.4749)  loss_giou: 1.9173 (2.0085)  loss_ce_0: 1.2638 (1.5862)  loss_bbox_0: 0.3995 (0.7648)  loss_giou_0: 2.3257 (2.2839)  loss_ce_1: 2.0516 (2.2300)  loss_bbox_1: 0.3073 (0.5979)  loss_giou_1: 2.0737 (2.1005)  loss_ce_2: 1.2158 (1.4677)  loss_bbox_2: 0.2438 (0.5085)  loss_giou_2: 1.9396 (2.0373)  time: 0.6169 (0.8962)  data: 0.0006 (0.0532)  lr: 0.000003  max mem: 6046
2024-04-09 19:51:58,928 mega_core INFO: Using 1 GPUs
2024-04-09 19:51:58,961 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 19:51:58,961 mega_core INFO: Collecting env info (might take some time)
2024-04-09 19:52:04,187 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 19:52:04,188 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 19:52:04,189 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 19:52:04,192 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 19:52:04,193 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 19:52:26,056 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:02:34,070 mega_core INFO: Using 1 GPUs
2024-04-09 20:02:34,071 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:02:34,071 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:02:35,579 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:02:35,580 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:02:35,580 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:02:35,582 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:02:35,583 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:02:40,876 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:03:34,073 mega_core INFO: Using 1 GPUs
2024-04-09 20:03:34,074 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:03:34,074 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:03:35,621 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:03:35,621 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:03:35,622 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:03:35,625 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:03:35,625 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:03:40,334 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:06:28,754 mega_core INFO: Using 1 GPUs
2024-04-09 20:06:28,755 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:06:28,755 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:06:30,293 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:06:30,294 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:06:30,294 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:06:30,297 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:06:30,297 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:06:35,511 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:06:42,377 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:35:27,767 mega_core INFO: Using 1 GPUs
2024-04-09 20:35:27,767 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:35:27,768 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:35:29,266 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:35:29,266 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:35:29,267 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:35:29,269 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:35:29,269 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:35:34,307 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:35:36,480 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:37:09,074 mega_core INFO: Using 1 GPUs
2024-04-09 20:37:09,074 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:37:09,074 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:37:10,504 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:37:10,504 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:37:10,504 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:37:10,507 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:37:10,507 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:37:15,412 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:37:17,594 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:37:18,510 mega_core.trainer INFO: Start training
2024-04-09 20:40:10,750 mega_core INFO: Using 1 GPUs
2024-04-09 20:40:10,750 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:40:10,751 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:40:12,387 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:40:12,388 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:40:12,388 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:40:12,391 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:40:12,392 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:40:17,389 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:40:19,739 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:40:20,725 mega_core.trainer INFO: Start training
2024-04-09 20:41:00,407 mega_core INFO: Using 1 GPUs
2024-04-09 20:41:00,407 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:41:00,407 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:41:01,986 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:41:01,987 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:41:01,987 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:41:01,989 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:41:01,990 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:41:06,870 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:41:09,015 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:41:09,930 mega_core.trainer INFO: Start training
2024-04-09 20:42:31,530 mega_core INFO: Using 1 GPUs
2024-04-09 20:42:31,530 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:42:31,531 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:42:32,997 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:42:32,997 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:42:32,998 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:42:33,000 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:42:33,001 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:42:37,857 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:44:45,175 mega_core INFO: Using 1 GPUs
2024-04-09 20:44:45,176 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:44:45,176 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:44:46,668 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:44:46,668 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:44:46,669 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:44:46,671 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:44:46,671 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:44:51,593 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:44:53,764 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:44:54,677 mega_core.trainer INFO: Start training
2024-04-09 20:45:56,910 mega_core INFO: Using 1 GPUs
2024-04-09 20:45:56,910 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:45:56,910 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:45:58,430 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:45:58,431 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:45:58,431 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:45:58,434 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:45:58,435 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:46:03,537 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:46:05,902 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:46:06,914 mega_core.trainer INFO: Start training
2024-04-09 20:48:32,500 mega_core INFO: Using 1 GPUs
2024-04-09 20:48:32,501 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-09 20:48:32,501 mega_core INFO: Collecting env info (might take some time)
2024-04-09 20:48:34,028 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-09 20:48:34,029 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-09 20:48:34,029 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 11
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (40000, 60000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 65000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 13727 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 2  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-09 20:48:34,032 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 11
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 2
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 65000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (40000, 60000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 13727
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-09 20:48:34,033 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-09 20:48:38,834 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-09 20:52:32,397 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-09 20:52:33,261 mega_core.trainer INFO: Start training
2024-04-09 20:54:30,926 mega_core.trainer INFO: eta: 4 days, 10:11:12  iter: 21  loss: 13.4465 (15.0108)  loss_ce: 1.5400 (1.7104)  loss_bbox: 0.2814 (0.4146)  loss_giou: 1.3185 (1.3953)  loss_ce_0: 1.3825 (1.6024)  loss_bbox_0: 0.4298 (0.6179)  loss_giou_0: 1.9428 (1.8766)  loss_ce_1: 1.6491 (1.8135)  loss_bbox_1: 0.4084 (0.4810)  loss_giou_1: 1.5369 (1.5305)  loss_ce_2: 1.4381 (1.6943)  loss_bbox_2: 0.3041 (0.4382)  loss_giou_2: 1.3485 (1.4362)  time: 0.5054 (2.9415)  data: 0.0005 (2.2718)  lr: 0.000003  max mem: 5455
2024-04-09 20:54:59,253 mega_core.trainer INFO: eta: 2 days, 17:51:19  iter: 41  loss: 11.5527 (13.7495)  loss_ce: 0.9400 (1.4164)  loss_bbox: 0.2939 (0.3977)  loss_giou: 1.3963 (1.3988)  loss_ce_0: 1.0469 (1.3939)  loss_bbox_0: 0.4319 (0.5668)  loss_giou_0: 1.8017 (1.8533)  loss_ce_1: 0.9935 (1.5176)  loss_bbox_1: 0.3902 (0.4576)  loss_giou_1: 1.4917 (1.4999)  loss_ce_2: 0.9153 (1.4058)  loss_bbox_2: 0.3084 (0.4170)  loss_giou_2: 1.4206 (1.4248)  time: 0.6156 (1.8248)  data: 0.0138 (1.1415)  lr: 0.000003  max mem: 5455
2024-04-09 20:55:27,055 mega_core.trainer INFO: eta: 2 days, 4:14:55  iter: 61  loss: 11.0655 (12.7458)  loss_ce: 0.7429 (1.2209)  loss_bbox: 0.3078 (0.3704)  loss_giou: 1.4506 (1.3673)  loss_ce_0: 0.8899 (1.2523)  loss_bbox_0: 0.3922 (0.5342)  loss_giou_0: 1.8481 (1.8218)  loss_ce_1: 0.7414 (1.3008)  loss_bbox_1: 0.3519 (0.4295)  loss_giou_1: 1.5127 (1.4695)  loss_ce_2: 0.7248 (1.2095)  loss_bbox_2: 0.3135 (0.3831)  loss_giou_2: 1.4092 (1.3867)  time: 0.5306 (1.4482)  data: 0.0144 (0.7660)  lr: 0.000003  max mem: 5455
2024-04-09 20:55:54,774 mega_core.trainer INFO: eta: 1 day, 21:25:22  iter: 81  loss: 10.9377 (12.0287)  loss_ce: 0.8018 (1.1017)  loss_bbox: 0.2476 (0.3437)  loss_giou: 1.2269 (1.3258)  loss_ce_0: 0.8591 (1.1538)  loss_bbox_0: 0.4952 (0.5118)  loss_giou_0: 1.8720 (1.7925)  loss_ce_1: 0.7811 (1.1660)  loss_bbox_1: 0.3460 (0.4041)  loss_giou_1: 1.4453 (1.4356)  loss_ce_2: 0.7128 (1.0868)  loss_bbox_2: 0.3073 (0.3579)  loss_giou_2: 1.3125 (1.3491)  time: 0.5906 (1.2594)  data: 0.0139 (0.5780)  lr: 0.000003  max mem: 5455
2024-04-09 20:56:22,518 mega_core.trainer INFO: eta: 1 day, 17:19:43  iter: 101  loss: 9.3775 (11.5573)  loss_ce: 0.6687 (1.0231)  loss_bbox: 0.2850 (0.3271)  loss_giou: 1.2595 (1.3019)  loss_ce_0: 0.7849 (1.0910)  loss_bbox_0: 0.4136 (0.4933)  loss_giou_0: 1.7130 (1.7708)  loss_ce_1: 0.6935 (1.0776)  loss_bbox_1: 0.2992 (0.3842)  loss_giou_1: 1.3731 (1.4131)  loss_ce_2: 0.6139 (1.0104)  loss_bbox_2: 0.2830 (0.3406)  loss_giou_2: 1.2192 (1.3242)  time: 0.6009 (1.1463)  data: 0.0134 (0.4652)  lr: 0.000003  max mem: 5455
2024-04-09 20:56:50,512 mega_core.trainer INFO: eta: 1 day, 14:38:03  iter: 121  loss: 9.3560 (11.2299)  loss_ce: 0.6071 (0.9664)  loss_bbox: 0.2257 (0.3205)  loss_giou: 1.2025 (1.2786)  loss_ce_0: 0.7664 (1.0500)  loss_bbox_0: 0.3907 (0.4918)  loss_giou_0: 1.7553 (1.7518)  loss_ce_1: 0.6621 (1.0187)  loss_bbox_1: 0.2536 (0.3735)  loss_giou_1: 1.3032 (1.3898)  loss_ce_2: 0.5954 (0.9573)  loss_bbox_2: 0.2266 (0.3319)  loss_giou_2: 1.2159 (1.2998)  time: 0.6018 (1.0718)  data: 0.0134 (0.3900)  lr: 0.000003  max mem: 5455
2024-04-10 09:38:45,644 mega_core INFO: Using 1 GPUs
2024-04-10 09:38:45,645 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 09:38:45,645 mega_core INFO: Collecting env info (might take some time)
2024-04-10 09:38:48,070 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] mypy-extensions           1.0.0                    pypi_0    pypi
[conda] numpy                     1.23.5                   pypi_0    pypi
[conda] torch                     1.10.1+cu102             pypi_0    pypi
[conda] torchaudio                0.10.1+cu102             pypi_0    pypi
[conda] torchvision               0.11.2+cu102             pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 09:38:48,070 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 09:38:48,071 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 09:38:48,073 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 09:38:48,074 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 09:38:52,884 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 09:47:18,778 mega_core INFO: Using 1 GPUs
2024-04-10 09:47:18,779 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 09:47:18,779 mega_core INFO: Collecting env info (might take some time)
2024-04-10 09:47:21,115 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] mypy-extensions           1.0.0                    pypi_0    pypi
[conda] numpy                     1.23.5                   pypi_0    pypi
[conda] torch                     1.10.1+cu102             pypi_0    pypi
[conda] torchaudio                0.10.1+cu102             pypi_0    pypi
[conda] torchvision               0.11.2+cu102             pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 09:47:21,116 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 09:47:21,116 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 09:47:21,118 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 09:47:21,119 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 09:47:25,989 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 09:50:13,572 mega_core INFO: Using 1 GPUs
2024-04-10 09:50:13,573 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 09:50:13,573 mega_core INFO: Collecting env info (might take some time)
2024-04-10 09:50:15,075 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 09:50:15,075 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 09:50:15,076 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 09:50:15,078 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 09:50:15,078 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 09:50:19,972 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 09:57:10,801 mega_core INFO: Using 1 GPUs
2024-04-10 09:57:10,802 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 09:57:10,802 mega_core INFO: Collecting env info (might take some time)
2024-04-10 09:57:12,383 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 09:57:12,384 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 09:57:12,384 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 09:57:12,386 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 09:57:12,387 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 09:57:17,293 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 09:57:19,753 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-10 09:57:20,677 mega_core.trainer INFO: Start training
2024-04-10 09:58:18,075 mega_core INFO: Using 1 GPUs
2024-04-10 09:58:18,075 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 09:58:18,075 mega_core INFO: Collecting env info (might take some time)
2024-04-10 09:58:19,612 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 09:58:19,612 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 09:58:19,613 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 09:58:19,616 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 09:58:19,616 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 09:58:24,556 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 10:05:43,946 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-10 10:05:44,863 mega_core.trainer INFO: Start training
2024-04-10 10:11:33,294 mega_core INFO: Using 1 GPUs
2024-04-10 10:11:33,295 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 10:11:33,295 mega_core INFO: Collecting env info (might take some time)
2024-04-10 10:11:34,829 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 10:11:34,829 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 10:11:34,830 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 10:11:34,832 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 10:11:34,833 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 10:11:39,713 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 10:13:32,811 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-10 10:13:33,735 mega_core.trainer INFO: Start training
2024-04-10 10:14:42,608 mega_core.trainer INFO: eta: 1 day, 22:50:53  iter: 21  loss: 16.8470 (16.8785)  loss_ce: 2.3252 (2.3107)  loss_bbox: 0.3807 (0.3851)  loss_giou: 1.4847 (1.4514)  loss_ce_0: 2.0363 (2.0316)  loss_bbox_0: 0.5366 (0.5408)  loss_giou_0: 1.8594 (1.8756)  loss_ce_1: 2.2491 (2.2647)  loss_bbox_1: 0.4330 (0.4191)  loss_giou_1: 1.6367 (1.5732)  loss_ce_2: 2.0684 (2.1166)  loss_bbox_2: 0.4058 (0.4147)  loss_giou_2: 1.5447 (1.4950)  time: 1.2554 (3.4433)  data: 0.4872 (2.6748)  lr: 0.000003  max mem: 5457
2024-04-10 10:14:56,988 mega_core.trainer INFO: eta: 1 day, 4:18:13  iter: 41  loss: 13.8156 (15.5128)  loss_ce: 1.2997 (1.8085)  loss_bbox: 0.3357 (0.4296)  loss_giou: 1.2714 (1.4057)  loss_ce_0: 1.2913 (1.6907)  loss_bbox_0: 0.4092 (0.5543)  loss_giou_0: 1.7447 (1.8708)  loss_ce_1: 1.9022 (2.0762)  loss_bbox_1: 0.3729 (0.4514)  loss_giou_1: 1.3893 (1.5187)  loss_ce_2: 1.5507 (1.8259)  loss_bbox_2: 0.3254 (0.4423)  loss_giou_2: 1.3363 (1.4387)  time: 0.7061 (2.0812)  data: 0.0005 (1.3383)  lr: 0.000003  max mem: 5457
2024-04-10 10:15:11,710 mega_core.trainer INFO: eta: 22:11:49  iter: 61  loss: 12.2029 (14.3974)  loss_ce: 0.8312 (1.5108)  loss_bbox: 0.3592 (0.4047)  loss_giou: 1.3611 (1.3969)  loss_ce_0: 1.0712 (1.5052)  loss_bbox_0: 0.4347 (0.5366)  loss_giou_0: 1.8412 (1.8515)  loss_ce_1: 1.3292 (1.8324)  loss_bbox_1: 0.3585 (0.4398)  loss_giou_1: 1.5113 (1.5142)  loss_ce_2: 0.9832 (1.5567)  loss_bbox_2: 0.3537 (0.4202)  loss_giou_2: 1.3960 (1.4284)  time: 0.7152 (1.6328)  data: 0.0105 (0.8952)  lr: 0.000003  max mem: 5457
2024-04-10 10:15:26,889 mega_core.trainer INFO: eta: 19:13:09  iter: 81  loss: 9.9490 (13.4263)  loss_ce: 0.7170 (1.3259)  loss_bbox: 0.2583 (0.3775)  loss_giou: 1.1821 (1.3711)  loss_ce_0: 0.8889 (1.3605)  loss_bbox_0: 0.3906 (0.5128)  loss_giou_0: 1.7247 (1.8332)  loss_ce_1: 0.8265 (1.5893)  loss_bbox_1: 0.3189 (0.4170)  loss_giou_1: 1.2904 (1.4873)  loss_ce_2: 0.7054 (1.3611)  loss_bbox_2: 0.2632 (0.3898)  loss_giou_2: 1.1833 (1.4008)  time: 0.7523 (1.4143)  data: 0.0117 (0.6747)  lr: 0.000003  max mem: 5517
2024-04-10 10:15:50,312 mega_core INFO: Using 1 GPUs
2024-04-10 10:15:50,313 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 10:15:50,313 mega_core INFO: Collecting env info (might take some time)
2024-04-10 10:15:51,834 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 10:15:51,835 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 10:15:51,835 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 10:15:51,837 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 10:15:51,838 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 10:15:56,723 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 10:16:09,482 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-10 10:16:10,461 mega_core.trainer INFO: Start training
2024-04-10 10:16:28,751 mega_core.trainer INFO: eta: 12:26:14  iter: 21  loss: 16.1990 (16.0066)  loss_ce: 1.6015 (1.6739)  loss_bbox: 0.4124 (0.4594)  loss_giou: 1.5505 (1.5263)  loss_ce_0: 1.8035 (1.8335)  loss_bbox_0: 0.6304 (0.6009)  loss_giou_0: 1.9793 (1.9466)  loss_ce_1: 2.0586 (1.9567)  loss_bbox_1: 0.5215 (0.5225)  loss_giou_1: 1.6567 (1.6329)  loss_ce_2: 1.8116 (1.8163)  loss_bbox_2: 0.4238 (0.4852)  loss_giou_2: 1.5947 (1.5523)  time: 0.7953 (0.9141)  data: 0.0340 (0.1142)  lr: 0.000003  max mem: 5453
2024-04-10 10:16:43,250 mega_core.trainer INFO: eta: 11:08:45  iter: 41  loss: 12.2863 (14.1925)  loss_ce: 0.9796 (1.3574)  loss_bbox: 0.2916 (0.3979)  loss_giou: 1.4412 (1.4322)  loss_ce_0: 1.2906 (1.5879)  loss_bbox_0: 0.4303 (0.5555)  loss_giou_0: 1.8833 (1.8678)  loss_ce_1: 1.1220 (1.5808)  loss_bbox_1: 0.3360 (0.4520)  loss_giou_1: 1.5230 (1.5344)  loss_ce_2: 1.2856 (1.5584)  loss_bbox_2: 0.2887 (0.4082)  loss_giou_2: 1.3939 (1.4598)  time: 0.7120 (0.8196)  data: 0.0006 (0.0587)  lr: 0.000003  max mem: 5453
2024-04-10 10:16:57,780 mega_core.trainer INFO: eta: 10:43:11  iter: 61  loss: 11.5131 (13.2339)  loss_ce: 0.8238 (1.1982)  loss_bbox: 0.2668 (0.3741)  loss_giou: 1.3082 (1.3994)  loss_ce_0: 1.0422 (1.4334)  loss_bbox_0: 0.4352 (0.5200)  loss_giou_0: 1.8228 (1.8386)  loss_ce_1: 0.8065 (1.3556)  loss_bbox_1: 0.3084 (0.4241)  loss_giou_1: 1.4715 (1.5080)  loss_ce_2: 0.9387 (1.3694)  loss_bbox_2: 0.2679 (0.3832)  loss_giou_2: 1.3833 (1.4300)  time: 0.7175 (0.7885)  data: 0.0138 (0.0431)  lr: 0.000003  max mem: 5453
2024-04-10 10:17:12,303 mega_core.trainer INFO: eta: 10:30:12  iter: 81  loss: 10.2323 (12.4885)  loss_ce: 0.6815 (1.0836)  loss_bbox: 0.2416 (0.3532)  loss_giou: 1.2613 (1.3544)  loss_ce_0: 0.9149 (1.3116)  loss_bbox_0: 0.4022 (0.5046)  loss_giou_0: 1.8112 (1.8091)  loss_ce_1: 0.7171 (1.2136)  loss_bbox_1: 0.2999 (0.4027)  loss_giou_1: 1.4000 (1.4718)  loss_ce_2: 0.7592 (1.2348)  loss_bbox_2: 0.2596 (0.3624)  loss_giou_2: 1.2662 (1.3865)  time: 0.7263 (0.7730)  data: 0.0140 (0.0360)  lr: 0.000003  max mem: 5453
2024-04-10 10:17:27,033 mega_core.trainer INFO: eta: 10:24:00  iter: 101  loss: 8.4776 (11.9577)  loss_ce: 0.6911 (1.0117)  loss_bbox: 0.2114 (0.3394)  loss_giou: 1.0958 (1.3216)  loss_ce_0: 0.8406 (1.2294)  loss_bbox_0: 0.3602 (0.4848)  loss_giou_0: 1.5357 (1.7777)  loss_ce_1: 0.6796 (1.1206)  loss_bbox_1: 0.2622 (0.3892)  loss_giou_1: 1.1614 (1.4410)  loss_ce_2: 0.6941 (1.1347)  loss_bbox_2: 0.2345 (0.3499)  loss_giou_2: 1.1026 (1.3577)  time: 0.7316 (0.7657)  data: 0.0147 (0.0318)  lr: 0.000003  max mem: 5453
2024-04-10 10:17:42,296 mega_core.trainer INFO: eta: 10:23:24  iter: 121  loss: 10.5307 (11.6396)  loss_ce: 0.6561 (0.9541)  loss_bbox: 0.2825 (0.3340)  loss_giou: 1.2823 (1.3098)  loss_ce_0: 0.8157 (1.1668)  loss_bbox_0: 0.4142 (0.4841)  loss_giou_0: 1.7892 (1.7715)  loss_ce_1: 0.7190 (1.0545)  loss_bbox_1: 0.3236 (0.3824)  loss_giou_1: 1.4641 (1.4332)  loss_ce_2: 0.6958 (1.0598)  loss_bbox_2: 0.2961 (0.3430)  loss_giou_2: 1.3278 (1.3462)  time: 0.7462 (0.7652)  data: 0.0110 (0.0285)  lr: 0.000003  max mem: 5453
2024-04-10 10:17:57,379 mega_core.trainer INFO: eta: 10:21:52  iter: 141  loss: 9.5520 (11.3447)  loss_ce: 0.6214 (0.9120)  loss_bbox: 0.2423 (0.3233)  loss_giou: 1.2388 (1.2920)  loss_ce_0: 0.8032 (1.1200)  loss_bbox_0: 0.4156 (0.4753)  loss_giou_0: 1.7241 (1.7629)  loss_ce_1: 0.6706 (1.0051)  loss_bbox_1: 0.2900 (0.3712)  loss_giou_1: 1.3726 (1.4163)  loss_ce_2: 0.6547 (1.0055)  loss_bbox_2: 0.2635 (0.3327)  loss_giou_2: 1.2687 (1.3283)  time: 0.7439 (0.7637)  data: 0.0107 (0.0262)  lr: 0.000003  max mem: 5453
2024-04-10 10:18:12,444 mega_core.trainer INFO: eta: 10:20:33  iter: 161  loss: 9.8589 (11.1944)  loss_ce: 0.6196 (0.8849)  loss_bbox: 0.2442 (0.3202)  loss_giou: 1.2696 (1.2876)  loss_ce_0: 0.8091 (1.0903)  loss_bbox_0: 0.4189 (0.4743)  loss_giou_0: 1.7890 (1.7634)  loss_ce_1: 0.6737 (0.9727)  loss_bbox_1: 0.3175 (0.3677)  loss_giou_1: 1.3698 (1.4105)  loss_ce_2: 0.6530 (0.9693)  loss_bbox_2: 0.2983 (0.3307)  loss_giou_2: 1.3323 (1.3228)  time: 0.7491 (0.7624)  data: 0.0108 (0.0244)  lr: 0.000003  max mem: 5453
2024-04-10 10:20:46,536 mega_core INFO: Using 1 GPUs
2024-04-10 10:20:46,536 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 10:20:46,537 mega_core INFO: Collecting env info (might take some time)
2024-04-10 10:20:48,046 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 10:20:48,047 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 10:20:48,047 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 10:20:48,050 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 10:20:48,050 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 10:20:53,023 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-10 10:23:57,306 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-10 10:23:58,198 mega_core.trainer INFO: Start training
2024-04-10 10:25:07,711 mega_core INFO: Using 1 GPUs
2024-04-10 10:25:07,712 mega_core INFO: Namespace(config_file='configs/vid_R_101_DiffusionVID_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-10 10:25:07,712 mega_core INFO: Collecting env info (might take some time)
2024-04-10 10:25:09,291 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-10 10:25:09,292 mega_core INFO: Loaded configuration file configs/vid_R_101_DiffusionVID_UAVTOD.yaml
2024-04-10 10:25:09,292 mega_core INFO: 
MODEL:
  META_ARCHITECTURE: "DiffusionDet"
  WEIGHT: "pth/DiffusionVID_R101.pth"
  BACKBONE:
    NAME: "build_resnet_fpn_backbone"
    CONV_BODY: "R-101-torchvision"
  RESNETS:
    OUT_FEATURES: ["res2", "res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    DEPTH: 101
    STRIDE_IN_1X1: False
    RES5_DILATION: 1
  FPN:
    IN_FEATURES: ["res3", "res4", "res5"]  # ["res2", "res3", "res4", "res5"]
    OUT_CHANNELS: 256
  ROI_HEADS:
    IN_FEATURES: ["p3", "p4", "p5"]  # ["p2", "p3", "p4", "p5"]
  ROI_BOX_HEAD:
    POOLER_TYPE: "ROIAlignV2"
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
  DiffusionDet:
    NUM_PROPOSALS: 300  # 500
    NUM_CLASSES: 8
    HIDDEN_DIM: 256
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    SAMPLE_STEP: 1
  VID:
    METHOD: "diffusion"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: False  # local attention
        STAGE: 1  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 7
      ALL_FRAME_INTERVAL: 8
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 1
        SIZE: 24  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, t
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 5000
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATALOADER:
  SIZE_DIVISIBILITY: 32  # essential because of FPN
  NUM_WORKERS: 16  # 1 for debug
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
INPUT:
  PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
  PIXEL_STD: [ 58.395, 57.120, 57.375 ]
  TO_BGR255: False # pretrained torchvision weight use RGB format.
  TRANSFORM: True
  INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-10 10:25:09,294 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 16
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 32
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 8
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: False
  TRANSFORM: True
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-torchvision
    FREEZE_AT: 2
    FREEZE_CONV_BODY_AT: 2
    NAME: build_resnet_fpn_backbone
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  DiffusionDet:
    ACTIVATION: relu
    ALPHA: 0.25
    CLASS_WEIGHT: 2.0
    DEEP_SUPERVISION: True
    DIM_DYNAMIC: 64
    DIM_FEEDFORWARD: 2048
    DROPOUT: 0.0
    GAMMA: 2.0
    GIOU_WEIGHT: 2.0
    HIDDEN_DIM: 256
    L1_WEIGHT: 5.0
    NHEADS: 8
    NO_OBJECT_WEIGHT: 0.1
    NUM_CLASSES: 8
    NUM_CLS: 1
    NUM_DYNAMIC: 2
    NUM_HEADS: 3
    NUM_HEADS_LOCAL: 1
    NUM_PROPOSALS: 300
    NUM_REG: 3
    OTA_K: 5
    PRIOR_PROB: 0.01
    SAMPLE_STEP: 1
    SNR_SCALE: 2.0
    USE_FED_LOSS: False
    USE_FOCAL: True
    USE_NMS: True
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: ['res3', 'res4', 'res5']
    NORM: 
    OUT_CHANNELS: 256
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: DiffusionDet
  PIXEL_MEAN: [123.675, 116.28, 103.53]
  PIXEL_STD: [58.395, 57.12, 57.375]
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: (False, False, False, False)
    DEPTH: 101
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res2', 'res3', 'res4', 'res5']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: False
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 2
    POOLER_SCALES: (0.0625,)
    POOLER_TYPE: ROIAlignV2
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    IN_FEATURES: ['p3', 'p4', 'p5']
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  SWIN:
    OUT_FEATURES: (0, 1, 2, 3)
    SIZE: B
    USE_CHECKPOINT: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 8
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 24
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 0
      LOCAL:
        ENABLE: False
        PIXEL_ATTEND: False
      MAX_OFFSET: 7
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 1024
      MEMORY_MANAGEMENT_SIZE_TRAIN: 512
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: 0
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: diffusion
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 1
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: pth/DiffusionVID_R101.pth
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 1.0
    ENABLED: True
    NORM_TYPE: 2.0
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER: ADAMW
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 5000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-10 10:25:09,295 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-10 10:25:14,180 mega_core.utils.checkpoint INFO: Loading checkpoint from pth/DiffusionVID_R101.pth
2024-04-12 19:25:51,707 mega_core INFO: Using 1 GPUs
2024-04-12 19:25:51,707 mega_core INFO: Namespace(config_file='configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-12 19:25:51,708 mega_core INFO: Collecting env info (might take some time)
2024-04-12 19:25:53,317 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-12 19:25:53,318 mega_core INFO: Loaded configuration file configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml
2024-04-12 19:25:53,318 mega_core INFO: 
MODEL:
  VID:
    METHOD: "mega"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: True  # local attention
        STAGE: 3  # local attention stages
    MEGA:
      MIN_OFFSET: -12
      MAX_OFFSET: 12
      ALL_FRAME_INTERVAL: 25
      KEY_FRAME_LOCATION: 12
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: True  # local attention
        PIXEL_ATTEND: False
      MEMORY:
        ENABLE: True  # long range memory
        SIZE: 25
      GLOBAL:
        ENABLE: True  # global attention
        RES_STAGE: 1
        SIZE: 10  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: False
        BOX_ATTEND: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
      MHA: False
      REF_NUM_GLOBAL: 2  # ref num in training phase
      MEMORY_MANAGEMENT_METRIC: "queue"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "none"  # once, twice, sequential, greedy, random
  META_ARCHITECTURE: "GeneralizedRCNNMEGA"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-C4"
  ROI_BOX_HEAD:
    FEATURE_EXTRACTOR: "MEGAFeatureExtractor"
    PREDICTOR: "FPNPredictor"
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 100
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
# INPUT:
#   PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
#   PIXEL_STD: [ 58.395, 57.120, 57.375 ]
#   TO_BGR255: False # pretrained torchvision weight use RGB format.
#   TRANSFORM: True
#   INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-12 19:25:53,322 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 8
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 0
DATASETS:
  TEST: ('VID_val_frames',)
  TRAIN: ('DET_train_30classes', 'VID_train_15frames')
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 1
  MAX_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 1024
  MIN_SIZE_TEST: 960
  MIN_SIZE_TRAIN: (960,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: True
  TRANSFORM: False
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-50-C4
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNN
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 2
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 9
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FastRCNNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 25
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 50
        STOP_UPDATE_AFTER_INIT_TEST: True
      KEY_FRAME_LOCATION: 12
      LOCAL:
        ENABLE: True
        PIXEL_ATTEND: False
      MAX_OFFSET: 12
      MEMORY:
        ENABLE: False
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: distance
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 750
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: greedy
      MHA: False
      MIN_OFFSET: -12
      RATIO: 0.2
      REF_NUM_GLOBAL: 4
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: base
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: False
        GROUP: 16
        STAGE: 2
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: 
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 1
  BASE_LR: 0.001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 2
  CHECKPOINT_PERIOD: 20000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0
    ENABLED: False
  GAMMA: 0.1
  IMS_PER_BATCH: 3
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 160000
  MOMENTUM: 0.9
  OPTIMIZER_TYPE: sgd
  STEPS: (100000,)
  TEST_PERIOD: 40000
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 500
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 3
  SEQ_NMS: False
2024-04-12 19:25:53,323 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-12 19:25:57,060 mega_core.utils.checkpoint INFO: No checkpoint found. Initializing model from scratch
2024-04-12 19:25:57,060 mega_core.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-04-12 19:34:58,859 mega_core INFO: Using 1 GPUs
2024-04-12 19:34:58,860 mega_core INFO: Namespace(config_file='configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-12 19:34:58,861 mega_core INFO: Collecting env info (might take some time)
2024-04-12 19:35:00,454 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-12 19:35:00,454 mega_core INFO: Loaded configuration file configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml
2024-04-12 19:35:00,455 mega_core INFO: 
MODEL:
  VID:
    METHOD: "mega"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: True  # local attention
        STAGE: 3  # local attention stages
    MEGA:
      MIN_OFFSET: -12
      MAX_OFFSET: 12
      ALL_FRAME_INTERVAL: 25
      KEY_FRAME_LOCATION: 12
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: True  # local attention
        PIXEL_ATTEND: False
      MEMORY:
        ENABLE: True  # long range memory
        SIZE: 25
      GLOBAL:
        ENABLE: True  # global attention
        RES_STAGE: 1
        SIZE: 10  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: False
        BOX_ATTEND: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
      MHA: False
      REF_NUM_GLOBAL: 2  # ref num in training phase
      MEMORY_MANAGEMENT_METRIC: "queue"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "none"  # once, twice, sequential, greedy, random
  META_ARCHITECTURE: "GeneralizedRCNNMEGA"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-C4"
  ROI_BOX_HEAD:
    FEATURE_EXTRACTOR: "MEGAFeatureExtractor"
    PREDICTOR: "FPNPredictor"
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 100
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
# INPUT:
#   PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
#   PIXEL_STD: [ 58.395, 57.120, 57.375 ]
#   TO_BGR255: False # pretrained torchvision weight use RGB format.
#   TRANSFORM: True
#   INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-12 19:35:00,457 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 8
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 0
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 1
  MAX_SIZE_TEST: 1024
  MAX_SIZE_TRAIN: 1024
  MIN_SIZE_TEST: 960
  MIN_SIZE_TRAIN: (960,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: True
  TRANSFORM: False
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-C4
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNNMEGA
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 2
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: MEGAFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 9
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 25
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 10
        STOP_UPDATE_AFTER_INIT_TEST: False
      KEY_FRAME_LOCATION: 12
      LOCAL:
        ENABLE: True
        PIXEL_ATTEND: False
      MAX_OFFSET: 12
      MEMORY:
        ENABLE: True
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: queue
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 750
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: none
      MHA: False
      MIN_OFFSET: -12
      RATIO: 0.2
      REF_NUM_GLOBAL: 2
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: mega
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: True
        GROUP: 16
        STAGE: 3
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-101
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0
    ENABLED: False
  GAMMA: 0.1
  IMS_PER_BATCH: 3
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 100
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 3
  SEQ_NMS: False
2024-04-12 19:35:00,457 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-12 19:35:06,595 mega_core.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-101
2024-04-12 19:35:06,596 mega_core.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-101 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl
2024-04-12 19:35:06,599 mega_core.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl cached in /home/jiahaoguo/.torch/models/R-101.pkl
2024-04-12 19:35:07,017 mega_core.utils.c2_model_loading INFO: Remapping C2 weights
2024-04-12 19:35:07,017 mega_core.utils.c2_model_loading INFO: C2 name: conv1_b               mapped name: conv1.bias
2024-04-12 19:35:07,017 mega_core.utils.c2_model_loading INFO: C2 name: conv1_w               mapped name: conv1.weight
2024-04-12 19:35:07,017 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_b              mapped name: fc1000.bias
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_w              mapped name: fc1000.weight
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b      mapped name: layer1.0.downsample.0.bias
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b   mapped name: layer1.0.downsample.1.bias
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s   mapped name: layer1.0.downsample.1.weight
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w      mapped name: layer1.0.downsample.0.weight
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b     mapped name: layer1.0.conv1.bias
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b  mapped name: layer1.0.bn1.bias
2024-04-12 19:35:07,018 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s  mapped name: layer1.0.bn1.weight
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w     mapped name: layer1.0.conv1.weight
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b     mapped name: layer1.0.conv2.bias
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b  mapped name: layer1.0.bn2.bias
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s  mapped name: layer1.0.bn2.weight
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w     mapped name: layer1.0.conv2.weight
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b     mapped name: layer1.0.conv3.bias
2024-04-12 19:35:07,019 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b  mapped name: layer1.0.bn3.bias
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s  mapped name: layer1.0.bn3.weight
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w     mapped name: layer1.0.conv3.weight
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b     mapped name: layer1.1.conv1.bias
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b  mapped name: layer1.1.bn1.bias
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s  mapped name: layer1.1.bn1.weight
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w     mapped name: layer1.1.conv1.weight
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b     mapped name: layer1.1.conv2.bias
2024-04-12 19:35:07,020 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b  mapped name: layer1.1.bn2.bias
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s  mapped name: layer1.1.bn2.weight
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w     mapped name: layer1.1.conv2.weight
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b     mapped name: layer1.1.conv3.bias
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b  mapped name: layer1.1.bn3.bias
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s  mapped name: layer1.1.bn3.weight
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w     mapped name: layer1.1.conv3.weight
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b     mapped name: layer1.2.conv1.bias
2024-04-12 19:35:07,021 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b  mapped name: layer1.2.bn1.bias
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s  mapped name: layer1.2.bn1.weight
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w     mapped name: layer1.2.conv1.weight
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b     mapped name: layer1.2.conv2.bias
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b  mapped name: layer1.2.bn2.bias
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s  mapped name: layer1.2.bn2.weight
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w     mapped name: layer1.2.conv2.weight
2024-04-12 19:35:07,022 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b     mapped name: layer1.2.conv3.bias
2024-04-12 19:35:07,023 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b  mapped name: layer1.2.bn3.bias
2024-04-12 19:35:07,023 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s  mapped name: layer1.2.bn3.weight
2024-04-12 19:35:07,023 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w     mapped name: layer1.2.conv3.weight
2024-04-12 19:35:07,023 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b      mapped name: layer2.0.downsample.0.bias
2024-04-12 19:35:07,023 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b   mapped name: layer2.0.downsample.1.bias
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s   mapped name: layer2.0.downsample.1.weight
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w      mapped name: layer2.0.downsample.0.weight
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b     mapped name: layer2.0.conv1.bias
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b  mapped name: layer2.0.bn1.bias
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s  mapped name: layer2.0.bn1.weight
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w     mapped name: layer2.0.conv1.weight
2024-04-12 19:35:07,024 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b     mapped name: layer2.0.conv2.bias
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b  mapped name: layer2.0.bn2.bias
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s  mapped name: layer2.0.bn2.weight
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w     mapped name: layer2.0.conv2.weight
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b     mapped name: layer2.0.conv3.bias
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b  mapped name: layer2.0.bn3.bias
2024-04-12 19:35:07,025 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s  mapped name: layer2.0.bn3.weight
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w     mapped name: layer2.0.conv3.weight
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b     mapped name: layer2.1.conv1.bias
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b  mapped name: layer2.1.bn1.bias
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s  mapped name: layer2.1.bn1.weight
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w     mapped name: layer2.1.conv1.weight
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b     mapped name: layer2.1.conv2.bias
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b  mapped name: layer2.1.bn2.bias
2024-04-12 19:35:07,026 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s  mapped name: layer2.1.bn2.weight
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w     mapped name: layer2.1.conv2.weight
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b     mapped name: layer2.1.conv3.bias
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b  mapped name: layer2.1.bn3.bias
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s  mapped name: layer2.1.bn3.weight
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w     mapped name: layer2.1.conv3.weight
2024-04-12 19:35:07,027 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b     mapped name: layer2.2.conv1.bias
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b  mapped name: layer2.2.bn1.bias
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s  mapped name: layer2.2.bn1.weight
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w     mapped name: layer2.2.conv1.weight
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b     mapped name: layer2.2.conv2.bias
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b  mapped name: layer2.2.bn2.bias
2024-04-12 19:35:07,028 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s  mapped name: layer2.2.bn2.weight
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w     mapped name: layer2.2.conv2.weight
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b     mapped name: layer2.2.conv3.bias
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b  mapped name: layer2.2.bn3.bias
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s  mapped name: layer2.2.bn3.weight
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w     mapped name: layer2.2.conv3.weight
2024-04-12 19:35:07,029 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b     mapped name: layer2.3.conv1.bias
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b  mapped name: layer2.3.bn1.bias
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s  mapped name: layer2.3.bn1.weight
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w     mapped name: layer2.3.conv1.weight
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b     mapped name: layer2.3.conv2.bias
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b  mapped name: layer2.3.bn2.bias
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s  mapped name: layer2.3.bn2.weight
2024-04-12 19:35:07,030 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w     mapped name: layer2.3.conv2.weight
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b     mapped name: layer2.3.conv3.bias
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b  mapped name: layer2.3.bn3.bias
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s  mapped name: layer2.3.bn3.weight
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w     mapped name: layer2.3.conv3.weight
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b      mapped name: layer3.0.downsample.0.bias
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b   mapped name: layer3.0.downsample.1.bias
2024-04-12 19:35:07,031 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s   mapped name: layer3.0.downsample.1.weight
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w      mapped name: layer3.0.downsample.0.weight
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b     mapped name: layer3.0.conv1.bias
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b  mapped name: layer3.0.bn1.bias
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s  mapped name: layer3.0.bn1.weight
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w     mapped name: layer3.0.conv1.weight
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b     mapped name: layer3.0.conv2.bias
2024-04-12 19:35:07,032 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b  mapped name: layer3.0.bn2.bias
2024-04-12 19:35:07,033 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s  mapped name: layer3.0.bn2.weight
2024-04-12 19:35:07,033 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w     mapped name: layer3.0.conv2.weight
2024-04-12 19:35:07,033 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b     mapped name: layer3.0.conv3.bias
2024-04-12 19:35:07,033 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b  mapped name: layer3.0.bn3.bias
2024-04-12 19:35:07,033 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s  mapped name: layer3.0.bn3.weight
2024-04-12 19:35:07,034 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w     mapped name: layer3.0.conv3.weight
2024-04-12 19:35:07,034 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_b    mapped name: layer3.10.conv1.bias
2024-04-12 19:35:07,034 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_b mapped name: layer3.10.bn1.bias
2024-04-12 19:35:07,034 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_s mapped name: layer3.10.bn1.weight
2024-04-12 19:35:07,035 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_w    mapped name: layer3.10.conv1.weight
2024-04-12 19:35:07,035 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_b    mapped name: layer3.10.conv2.bias
2024-04-12 19:35:07,035 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_b mapped name: layer3.10.bn2.bias
2024-04-12 19:35:07,035 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_s mapped name: layer3.10.bn2.weight
2024-04-12 19:35:07,036 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_w    mapped name: layer3.10.conv2.weight
2024-04-12 19:35:07,036 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_b    mapped name: layer3.10.conv3.bias
2024-04-12 19:35:07,036 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_b mapped name: layer3.10.bn3.bias
2024-04-12 19:35:07,036 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_s mapped name: layer3.10.bn3.weight
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_w    mapped name: layer3.10.conv3.weight
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_b    mapped name: layer3.11.conv1.bias
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_b mapped name: layer3.11.bn1.bias
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_s mapped name: layer3.11.bn1.weight
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_w    mapped name: layer3.11.conv1.weight
2024-04-12 19:35:07,037 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_b    mapped name: layer3.11.conv2.bias
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_b mapped name: layer3.11.bn2.bias
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_s mapped name: layer3.11.bn2.weight
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_w    mapped name: layer3.11.conv2.weight
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_b    mapped name: layer3.11.conv3.bias
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_b mapped name: layer3.11.bn3.bias
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_s mapped name: layer3.11.bn3.weight
2024-04-12 19:35:07,038 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_w    mapped name: layer3.11.conv3.weight
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_b    mapped name: layer3.12.conv1.bias
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_b mapped name: layer3.12.bn1.bias
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_s mapped name: layer3.12.bn1.weight
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_w    mapped name: layer3.12.conv1.weight
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_b    mapped name: layer3.12.conv2.bias
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_b mapped name: layer3.12.bn2.bias
2024-04-12 19:35:07,039 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_s mapped name: layer3.12.bn2.weight
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_w    mapped name: layer3.12.conv2.weight
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_b    mapped name: layer3.12.conv3.bias
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_b mapped name: layer3.12.bn3.bias
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_s mapped name: layer3.12.bn3.weight
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_w    mapped name: layer3.12.conv3.weight
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_b    mapped name: layer3.13.conv1.bias
2024-04-12 19:35:07,040 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_b mapped name: layer3.13.bn1.bias
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_s mapped name: layer3.13.bn1.weight
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_w    mapped name: layer3.13.conv1.weight
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_b    mapped name: layer3.13.conv2.bias
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_b mapped name: layer3.13.bn2.bias
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_s mapped name: layer3.13.bn2.weight
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_w    mapped name: layer3.13.conv2.weight
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_b    mapped name: layer3.13.conv3.bias
2024-04-12 19:35:07,041 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_b mapped name: layer3.13.bn3.bias
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_s mapped name: layer3.13.bn3.weight
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_w    mapped name: layer3.13.conv3.weight
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_b    mapped name: layer3.14.conv1.bias
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_b mapped name: layer3.14.bn1.bias
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_s mapped name: layer3.14.bn1.weight
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_w    mapped name: layer3.14.conv1.weight
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_b    mapped name: layer3.14.conv2.bias
2024-04-12 19:35:07,042 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_b mapped name: layer3.14.bn2.bias
2024-04-12 19:35:07,043 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_s mapped name: layer3.14.bn2.weight
2024-04-12 19:35:07,043 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_w    mapped name: layer3.14.conv2.weight
2024-04-12 19:35:07,043 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_b    mapped name: layer3.14.conv3.bias
2024-04-12 19:35:07,043 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_b mapped name: layer3.14.bn3.bias
2024-04-12 19:35:07,043 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_s mapped name: layer3.14.bn3.weight
2024-04-12 19:35:07,044 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_w    mapped name: layer3.14.conv3.weight
2024-04-12 19:35:07,044 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_b    mapped name: layer3.15.conv1.bias
2024-04-12 19:35:07,044 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_b mapped name: layer3.15.bn1.bias
2024-04-12 19:35:07,044 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_s mapped name: layer3.15.bn1.weight
2024-04-12 19:35:07,044 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_w    mapped name: layer3.15.conv1.weight
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_b    mapped name: layer3.15.conv2.bias
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_b mapped name: layer3.15.bn2.bias
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_s mapped name: layer3.15.bn2.weight
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_w    mapped name: layer3.15.conv2.weight
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_b    mapped name: layer3.15.conv3.bias
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_b mapped name: layer3.15.bn3.bias
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_s mapped name: layer3.15.bn3.weight
2024-04-12 19:35:07,045 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_w    mapped name: layer3.15.conv3.weight
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_b    mapped name: layer3.16.conv1.bias
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_b mapped name: layer3.16.bn1.bias
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_s mapped name: layer3.16.bn1.weight
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_w    mapped name: layer3.16.conv1.weight
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_b    mapped name: layer3.16.conv2.bias
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_b mapped name: layer3.16.bn2.bias
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_s mapped name: layer3.16.bn2.weight
2024-04-12 19:35:07,046 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_w    mapped name: layer3.16.conv2.weight
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_b    mapped name: layer3.16.conv3.bias
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_b mapped name: layer3.16.bn3.bias
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_s mapped name: layer3.16.bn3.weight
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_w    mapped name: layer3.16.conv3.weight
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_b    mapped name: layer3.17.conv1.bias
2024-04-12 19:35:07,047 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_b mapped name: layer3.17.bn1.bias
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_s mapped name: layer3.17.bn1.weight
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_w    mapped name: layer3.17.conv1.weight
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_b    mapped name: layer3.17.conv2.bias
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_b mapped name: layer3.17.bn2.bias
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_s mapped name: layer3.17.bn2.weight
2024-04-12 19:35:07,048 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_w    mapped name: layer3.17.conv2.weight
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_b    mapped name: layer3.17.conv3.bias
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_b mapped name: layer3.17.bn3.bias
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_s mapped name: layer3.17.bn3.weight
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_w    mapped name: layer3.17.conv3.weight
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_b    mapped name: layer3.18.conv1.bias
2024-04-12 19:35:07,049 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_b mapped name: layer3.18.bn1.bias
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_s mapped name: layer3.18.bn1.weight
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_w    mapped name: layer3.18.conv1.weight
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_b    mapped name: layer3.18.conv2.bias
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_b mapped name: layer3.18.bn2.bias
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_s mapped name: layer3.18.bn2.weight
2024-04-12 19:35:07,050 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_w    mapped name: layer3.18.conv2.weight
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_b    mapped name: layer3.18.conv3.bias
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_b mapped name: layer3.18.bn3.bias
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_s mapped name: layer3.18.bn3.weight
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_w    mapped name: layer3.18.conv3.weight
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_b    mapped name: layer3.19.conv1.bias
2024-04-12 19:35:07,051 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_b mapped name: layer3.19.bn1.bias
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_s mapped name: layer3.19.bn1.weight
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_w    mapped name: layer3.19.conv1.weight
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_b    mapped name: layer3.19.conv2.bias
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_b mapped name: layer3.19.bn2.bias
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_s mapped name: layer3.19.bn2.weight
2024-04-12 19:35:07,052 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_w    mapped name: layer3.19.conv2.weight
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_b    mapped name: layer3.19.conv3.bias
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_b mapped name: layer3.19.bn3.bias
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_s mapped name: layer3.19.bn3.weight
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_w    mapped name: layer3.19.conv3.weight
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b     mapped name: layer3.1.conv1.bias
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b  mapped name: layer3.1.bn1.bias
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s  mapped name: layer3.1.bn1.weight
2024-04-12 19:35:07,053 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w     mapped name: layer3.1.conv1.weight
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b     mapped name: layer3.1.conv2.bias
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b  mapped name: layer3.1.bn2.bias
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s  mapped name: layer3.1.bn2.weight
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w     mapped name: layer3.1.conv2.weight
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b     mapped name: layer3.1.conv3.bias
2024-04-12 19:35:07,054 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b  mapped name: layer3.1.bn3.bias
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s  mapped name: layer3.1.bn3.weight
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w     mapped name: layer3.1.conv3.weight
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_b    mapped name: layer3.20.conv1.bias
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_b mapped name: layer3.20.bn1.bias
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_s mapped name: layer3.20.bn1.weight
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_w    mapped name: layer3.20.conv1.weight
2024-04-12 19:35:07,055 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_b    mapped name: layer3.20.conv2.bias
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_b mapped name: layer3.20.bn2.bias
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_s mapped name: layer3.20.bn2.weight
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_w    mapped name: layer3.20.conv2.weight
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_b    mapped name: layer3.20.conv3.bias
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_b mapped name: layer3.20.bn3.bias
2024-04-12 19:35:07,056 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_s mapped name: layer3.20.bn3.weight
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_w    mapped name: layer3.20.conv3.weight
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_b    mapped name: layer3.21.conv1.bias
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_b mapped name: layer3.21.bn1.bias
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_s mapped name: layer3.21.bn1.weight
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_w    mapped name: layer3.21.conv1.weight
2024-04-12 19:35:07,057 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_b    mapped name: layer3.21.conv2.bias
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_b mapped name: layer3.21.bn2.bias
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_s mapped name: layer3.21.bn2.weight
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_w    mapped name: layer3.21.conv2.weight
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_b    mapped name: layer3.21.conv3.bias
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_b mapped name: layer3.21.bn3.bias
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_s mapped name: layer3.21.bn3.weight
2024-04-12 19:35:07,058 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_w    mapped name: layer3.21.conv3.weight
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_b    mapped name: layer3.22.conv1.bias
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_b mapped name: layer3.22.bn1.bias
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_s mapped name: layer3.22.bn1.weight
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_w    mapped name: layer3.22.conv1.weight
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_b    mapped name: layer3.22.conv2.bias
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_b mapped name: layer3.22.bn2.bias
2024-04-12 19:35:07,059 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_s mapped name: layer3.22.bn2.weight
2024-04-12 19:35:07,060 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_w    mapped name: layer3.22.conv2.weight
2024-04-12 19:35:07,060 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_b    mapped name: layer3.22.conv3.bias
2024-04-12 19:35:07,060 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_b mapped name: layer3.22.bn3.bias
2024-04-12 19:35:07,060 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_s mapped name: layer3.22.bn3.weight
2024-04-12 19:35:07,060 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_w    mapped name: layer3.22.conv3.weight
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b     mapped name: layer3.2.conv1.bias
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b  mapped name: layer3.2.bn1.bias
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s  mapped name: layer3.2.bn1.weight
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w     mapped name: layer3.2.conv1.weight
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b     mapped name: layer3.2.conv2.bias
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b  mapped name: layer3.2.bn2.bias
2024-04-12 19:35:07,061 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s  mapped name: layer3.2.bn2.weight
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w     mapped name: layer3.2.conv2.weight
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b     mapped name: layer3.2.conv3.bias
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b  mapped name: layer3.2.bn3.bias
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s  mapped name: layer3.2.bn3.weight
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w     mapped name: layer3.2.conv3.weight
2024-04-12 19:35:07,062 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b     mapped name: layer3.3.conv1.bias
2024-04-12 19:35:07,063 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b  mapped name: layer3.3.bn1.bias
2024-04-12 19:35:07,063 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s  mapped name: layer3.3.bn1.weight
2024-04-12 19:35:07,063 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w     mapped name: layer3.3.conv1.weight
2024-04-12 19:35:07,063 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b     mapped name: layer3.3.conv2.bias
2024-04-12 19:35:07,063 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b  mapped name: layer3.3.bn2.bias
2024-04-12 19:35:07,064 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s  mapped name: layer3.3.bn2.weight
2024-04-12 19:35:07,064 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w     mapped name: layer3.3.conv2.weight
2024-04-12 19:35:07,064 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b     mapped name: layer3.3.conv3.bias
2024-04-12 19:35:07,064 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b  mapped name: layer3.3.bn3.bias
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s  mapped name: layer3.3.bn3.weight
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w     mapped name: layer3.3.conv3.weight
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b     mapped name: layer3.4.conv1.bias
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b  mapped name: layer3.4.bn1.bias
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s  mapped name: layer3.4.bn1.weight
2024-04-12 19:35:07,065 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w     mapped name: layer3.4.conv1.weight
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b     mapped name: layer3.4.conv2.bias
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b  mapped name: layer3.4.bn2.bias
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s  mapped name: layer3.4.bn2.weight
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w     mapped name: layer3.4.conv2.weight
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b     mapped name: layer3.4.conv3.bias
2024-04-12 19:35:07,066 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b  mapped name: layer3.4.bn3.bias
2024-04-12 19:35:07,067 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s  mapped name: layer3.4.bn3.weight
2024-04-12 19:35:07,067 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w     mapped name: layer3.4.conv3.weight
2024-04-12 19:35:07,067 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b     mapped name: layer3.5.conv1.bias
2024-04-12 19:35:07,067 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b  mapped name: layer3.5.bn1.bias
2024-04-12 19:35:07,067 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s  mapped name: layer3.5.bn1.weight
2024-04-12 19:35:07,068 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w     mapped name: layer3.5.conv1.weight
2024-04-12 19:35:07,068 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b     mapped name: layer3.5.conv2.bias
2024-04-12 19:35:07,068 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b  mapped name: layer3.5.bn2.bias
2024-04-12 19:35:07,068 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s  mapped name: layer3.5.bn2.weight
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w     mapped name: layer3.5.conv2.weight
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b     mapped name: layer3.5.conv3.bias
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b  mapped name: layer3.5.bn3.bias
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s  mapped name: layer3.5.bn3.weight
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w     mapped name: layer3.5.conv3.weight
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_b     mapped name: layer3.6.conv1.bias
2024-04-12 19:35:07,069 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_b  mapped name: layer3.6.bn1.bias
2024-04-12 19:35:07,070 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_s  mapped name: layer3.6.bn1.weight
2024-04-12 19:35:07,070 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_w     mapped name: layer3.6.conv1.weight
2024-04-12 19:35:07,070 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_b     mapped name: layer3.6.conv2.bias
2024-04-12 19:35:07,070 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_b  mapped name: layer3.6.bn2.bias
2024-04-12 19:35:07,070 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_s  mapped name: layer3.6.bn2.weight
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_w     mapped name: layer3.6.conv2.weight
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_b     mapped name: layer3.6.conv3.bias
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_b  mapped name: layer3.6.bn3.bias
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_s  mapped name: layer3.6.bn3.weight
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_w     mapped name: layer3.6.conv3.weight
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_b     mapped name: layer3.7.conv1.bias
2024-04-12 19:35:07,071 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_b  mapped name: layer3.7.bn1.bias
2024-04-12 19:35:07,072 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_s  mapped name: layer3.7.bn1.weight
2024-04-12 19:35:07,072 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_w     mapped name: layer3.7.conv1.weight
2024-04-12 19:35:07,072 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_b     mapped name: layer3.7.conv2.bias
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_b  mapped name: layer3.7.bn2.bias
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_s  mapped name: layer3.7.bn2.weight
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_w     mapped name: layer3.7.conv2.weight
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_b     mapped name: layer3.7.conv3.bias
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_b  mapped name: layer3.7.bn3.bias
2024-04-12 19:35:07,073 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_s  mapped name: layer3.7.bn3.weight
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_w     mapped name: layer3.7.conv3.weight
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_b     mapped name: layer3.8.conv1.bias
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_b  mapped name: layer3.8.bn1.bias
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_s  mapped name: layer3.8.bn1.weight
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_w     mapped name: layer3.8.conv1.weight
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_b     mapped name: layer3.8.conv2.bias
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_b  mapped name: layer3.8.bn2.bias
2024-04-12 19:35:07,074 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_s  mapped name: layer3.8.bn2.weight
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_w     mapped name: layer3.8.conv2.weight
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_b     mapped name: layer3.8.conv3.bias
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_b  mapped name: layer3.8.bn3.bias
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_s  mapped name: layer3.8.bn3.weight
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_w     mapped name: layer3.8.conv3.weight
2024-04-12 19:35:07,075 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_b     mapped name: layer3.9.conv1.bias
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_b  mapped name: layer3.9.bn1.bias
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_s  mapped name: layer3.9.bn1.weight
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_w     mapped name: layer3.9.conv1.weight
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_b     mapped name: layer3.9.conv2.bias
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_b  mapped name: layer3.9.bn2.bias
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_s  mapped name: layer3.9.bn2.weight
2024-04-12 19:35:07,076 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_w     mapped name: layer3.9.conv2.weight
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_b     mapped name: layer3.9.conv3.bias
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_b  mapped name: layer3.9.bn3.bias
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_s  mapped name: layer3.9.bn3.weight
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_w     mapped name: layer3.9.conv3.weight
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b      mapped name: layer4.0.downsample.0.bias
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b   mapped name: layer4.0.downsample.1.bias
2024-04-12 19:35:07,077 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s   mapped name: layer4.0.downsample.1.weight
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w      mapped name: layer4.0.downsample.0.weight
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b     mapped name: layer4.0.conv1.bias
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b  mapped name: layer4.0.bn1.bias
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s  mapped name: layer4.0.bn1.weight
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w     mapped name: layer4.0.conv1.weight
2024-04-12 19:35:07,078 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b     mapped name: layer4.0.conv2.bias
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b  mapped name: layer4.0.bn2.bias
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s  mapped name: layer4.0.bn2.weight
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w     mapped name: layer4.0.conv2.weight
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b     mapped name: layer4.0.conv3.bias
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b  mapped name: layer4.0.bn3.bias
2024-04-12 19:35:07,079 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s  mapped name: layer4.0.bn3.weight
2024-04-12 19:35:07,080 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w     mapped name: layer4.0.conv3.weight
2024-04-12 19:35:07,080 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b     mapped name: layer4.1.conv1.bias
2024-04-12 19:35:07,080 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b  mapped name: layer4.1.bn1.bias
2024-04-12 19:35:07,080 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s  mapped name: layer4.1.bn1.weight
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w     mapped name: layer4.1.conv1.weight
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b     mapped name: layer4.1.conv2.bias
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b  mapped name: layer4.1.bn2.bias
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s  mapped name: layer4.1.bn2.weight
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w     mapped name: layer4.1.conv2.weight
2024-04-12 19:35:07,081 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b     mapped name: layer4.1.conv3.bias
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b  mapped name: layer4.1.bn3.bias
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s  mapped name: layer4.1.bn3.weight
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w     mapped name: layer4.1.conv3.weight
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b     mapped name: layer4.2.conv1.bias
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b  mapped name: layer4.2.bn1.bias
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s  mapped name: layer4.2.bn1.weight
2024-04-12 19:35:07,082 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w     mapped name: layer4.2.conv1.weight
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b     mapped name: layer4.2.conv2.bias
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b  mapped name: layer4.2.bn2.bias
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s  mapped name: layer4.2.bn2.weight
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w     mapped name: layer4.2.conv2.weight
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b     mapped name: layer4.2.conv3.bias
2024-04-12 19:35:07,083 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b  mapped name: layer4.2.bn3.bias
2024-04-12 19:35:07,084 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s  mapped name: layer4.2.bn3.weight
2024-04-12 19:35:07,084 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w     mapped name: layer4.2.conv3.weight
2024-04-12 19:35:07,084 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b        mapped name: bn1.bias
2024-04-12 19:35:07,084 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s        mapped name: bn1.weight
2024-04-12 19:35:07,084 mega_core.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2024-04-12 19:35:07,270 mega_core.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-04-12 19:35:08,925 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-12 19:35:08,951 mega_core.data.build WARNING: When using more than one image per GPU you may encounter an out-of-memory (OOM) error if your GPU does not have sufficient memory. If this happens, you can reduce SOLVER.IMS_PER_BATCH (for training) or TEST.IMS_PER_BATCH (for inference). For training, you must also adjust the learning rate and schedule length according to the linear scaling rule. See for example: https://github.com/facebookresearch/Detectron/blob/master/configs/getting_started/tutorial_1gpu_e2e_faster_rcnn_R-50-FPN.yaml#L14
2024-04-12 19:35:09,706 mega_core.trainer INFO: Start training
2024-04-12 19:36:05,785 mega_core INFO: Using 1 GPUs
2024-04-12 19:36:05,786 mega_core INFO: Namespace(config_file='configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-12 19:36:05,786 mega_core INFO: Collecting env info (might take some time)
2024-04-12 19:36:07,341 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-12 19:36:07,342 mega_core INFO: Loaded configuration file configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml
2024-04-12 19:36:07,342 mega_core INFO: 
MODEL:
  VID:
    METHOD: "mega"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: True  # local attention
        STAGE: 3  # local attention stages
    MEGA:
      MIN_OFFSET: -12
      MAX_OFFSET: 12
      ALL_FRAME_INTERVAL: 25
      KEY_FRAME_LOCATION: 12
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: True  # local attention
        PIXEL_ATTEND: False
      MEMORY:
        ENABLE: True  # long range memory
        SIZE: 25
      GLOBAL:
        ENABLE: True  # global attention
        RES_STAGE: 1
        SIZE: 10  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: False
        BOX_ATTEND: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
      MHA: False
      REF_NUM_GLOBAL: 2  # ref num in training phase
      MEMORY_MANAGEMENT_METRIC: "queue"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "none"  # once, twice, sequential, greedy, random
  META_ARCHITECTURE: "GeneralizedRCNNMEGA"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-C4"
  ROI_BOX_HEAD:
    FEATURE_EXTRACTOR: "MEGAFeatureExtractor"
    PREDICTOR: "FPNPredictor"
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 100
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
# INPUT:
#   PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
#   PIXEL_STD: [ 58.395, 57.120, 57.375 ]
#   TO_BGR255: False # pretrained torchvision weight use RGB format.
#   TRANSFORM: True
#   INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-12 19:36:07,346 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 1
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 0
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 1
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: True
  TRANSFORM: False
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-C4
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNNMEGA
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 2
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: MEGAFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 25
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 10
        STOP_UPDATE_AFTER_INIT_TEST: False
      KEY_FRAME_LOCATION: 12
      LOCAL:
        ENABLE: True
        PIXEL_ATTEND: False
      MAX_OFFSET: 12
      MEMORY:
        ENABLE: True
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: queue
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 750
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: none
      MHA: False
      MIN_OFFSET: -12
      RATIO: 0.2
      REF_NUM_GLOBAL: 2
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: mega
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: True
        GROUP: 16
        STAGE: 3
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-101
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0
    ENABLED: False
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 100
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-12 19:36:07,347 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-12 19:36:13,484 mega_core.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-101
2024-04-12 19:36:13,486 mega_core.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-101 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl
2024-04-12 19:36:13,487 mega_core.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl cached in /home/jiahaoguo/.torch/models/R-101.pkl
2024-04-12 19:36:13,633 mega_core.utils.c2_model_loading INFO: Remapping C2 weights
2024-04-12 19:36:13,633 mega_core.utils.c2_model_loading INFO: C2 name: conv1_b               mapped name: conv1.bias
2024-04-12 19:36:13,633 mega_core.utils.c2_model_loading INFO: C2 name: conv1_w               mapped name: conv1.weight
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_b              mapped name: fc1000.bias
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_w              mapped name: fc1000.weight
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b      mapped name: layer1.0.downsample.0.bias
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b   mapped name: layer1.0.downsample.1.bias
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s   mapped name: layer1.0.downsample.1.weight
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w      mapped name: layer1.0.downsample.0.weight
2024-04-12 19:36:13,634 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b     mapped name: layer1.0.conv1.bias
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b  mapped name: layer1.0.bn1.bias
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s  mapped name: layer1.0.bn1.weight
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w     mapped name: layer1.0.conv1.weight
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b     mapped name: layer1.0.conv2.bias
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b  mapped name: layer1.0.bn2.bias
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s  mapped name: layer1.0.bn2.weight
2024-04-12 19:36:13,635 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w     mapped name: layer1.0.conv2.weight
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b     mapped name: layer1.0.conv3.bias
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b  mapped name: layer1.0.bn3.bias
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s  mapped name: layer1.0.bn3.weight
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w     mapped name: layer1.0.conv3.weight
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b     mapped name: layer1.1.conv1.bias
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b  mapped name: layer1.1.bn1.bias
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s  mapped name: layer1.1.bn1.weight
2024-04-12 19:36:13,636 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w     mapped name: layer1.1.conv1.weight
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b     mapped name: layer1.1.conv2.bias
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b  mapped name: layer1.1.bn2.bias
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s  mapped name: layer1.1.bn2.weight
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w     mapped name: layer1.1.conv2.weight
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b     mapped name: layer1.1.conv3.bias
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b  mapped name: layer1.1.bn3.bias
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s  mapped name: layer1.1.bn3.weight
2024-04-12 19:36:13,637 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w     mapped name: layer1.1.conv3.weight
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b     mapped name: layer1.2.conv1.bias
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b  mapped name: layer1.2.bn1.bias
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s  mapped name: layer1.2.bn1.weight
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w     mapped name: layer1.2.conv1.weight
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b     mapped name: layer1.2.conv2.bias
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b  mapped name: layer1.2.bn2.bias
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s  mapped name: layer1.2.bn2.weight
2024-04-12 19:36:13,638 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w     mapped name: layer1.2.conv2.weight
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b     mapped name: layer1.2.conv3.bias
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b  mapped name: layer1.2.bn3.bias
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s  mapped name: layer1.2.bn3.weight
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w     mapped name: layer1.2.conv3.weight
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b      mapped name: layer2.0.downsample.0.bias
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b   mapped name: layer2.0.downsample.1.bias
2024-04-12 19:36:13,639 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s   mapped name: layer2.0.downsample.1.weight
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w      mapped name: layer2.0.downsample.0.weight
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b     mapped name: layer2.0.conv1.bias
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b  mapped name: layer2.0.bn1.bias
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s  mapped name: layer2.0.bn1.weight
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w     mapped name: layer2.0.conv1.weight
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b     mapped name: layer2.0.conv2.bias
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b  mapped name: layer2.0.bn2.bias
2024-04-12 19:36:13,640 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s  mapped name: layer2.0.bn2.weight
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w     mapped name: layer2.0.conv2.weight
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b     mapped name: layer2.0.conv3.bias
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b  mapped name: layer2.0.bn3.bias
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s  mapped name: layer2.0.bn3.weight
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w     mapped name: layer2.0.conv3.weight
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b     mapped name: layer2.1.conv1.bias
2024-04-12 19:36:13,641 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b  mapped name: layer2.1.bn1.bias
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s  mapped name: layer2.1.bn1.weight
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w     mapped name: layer2.1.conv1.weight
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b     mapped name: layer2.1.conv2.bias
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b  mapped name: layer2.1.bn2.bias
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s  mapped name: layer2.1.bn2.weight
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w     mapped name: layer2.1.conv2.weight
2024-04-12 19:36:13,642 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b     mapped name: layer2.1.conv3.bias
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b  mapped name: layer2.1.bn3.bias
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s  mapped name: layer2.1.bn3.weight
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w     mapped name: layer2.1.conv3.weight
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b     mapped name: layer2.2.conv1.bias
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b  mapped name: layer2.2.bn1.bias
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s  mapped name: layer2.2.bn1.weight
2024-04-12 19:36:13,643 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w     mapped name: layer2.2.conv1.weight
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b     mapped name: layer2.2.conv2.bias
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b  mapped name: layer2.2.bn2.bias
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s  mapped name: layer2.2.bn2.weight
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w     mapped name: layer2.2.conv2.weight
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b     mapped name: layer2.2.conv3.bias
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b  mapped name: layer2.2.bn3.bias
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s  mapped name: layer2.2.bn3.weight
2024-04-12 19:36:13,644 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w     mapped name: layer2.2.conv3.weight
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b     mapped name: layer2.3.conv1.bias
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b  mapped name: layer2.3.bn1.bias
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s  mapped name: layer2.3.bn1.weight
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w     mapped name: layer2.3.conv1.weight
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b     mapped name: layer2.3.conv2.bias
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b  mapped name: layer2.3.bn2.bias
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s  mapped name: layer2.3.bn2.weight
2024-04-12 19:36:13,645 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w     mapped name: layer2.3.conv2.weight
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b     mapped name: layer2.3.conv3.bias
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b  mapped name: layer2.3.bn3.bias
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s  mapped name: layer2.3.bn3.weight
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w     mapped name: layer2.3.conv3.weight
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b      mapped name: layer3.0.downsample.0.bias
2024-04-12 19:36:13,646 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b   mapped name: layer3.0.downsample.1.bias
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s   mapped name: layer3.0.downsample.1.weight
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w      mapped name: layer3.0.downsample.0.weight
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b     mapped name: layer3.0.conv1.bias
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b  mapped name: layer3.0.bn1.bias
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s  mapped name: layer3.0.bn1.weight
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w     mapped name: layer3.0.conv1.weight
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b     mapped name: layer3.0.conv2.bias
2024-04-12 19:36:13,647 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b  mapped name: layer3.0.bn2.bias
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s  mapped name: layer3.0.bn2.weight
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w     mapped name: layer3.0.conv2.weight
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b     mapped name: layer3.0.conv3.bias
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b  mapped name: layer3.0.bn3.bias
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s  mapped name: layer3.0.bn3.weight
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w     mapped name: layer3.0.conv3.weight
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_b    mapped name: layer3.10.conv1.bias
2024-04-12 19:36:13,648 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_b mapped name: layer3.10.bn1.bias
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_s mapped name: layer3.10.bn1.weight
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_w    mapped name: layer3.10.conv1.weight
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_b    mapped name: layer3.10.conv2.bias
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_b mapped name: layer3.10.bn2.bias
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_s mapped name: layer3.10.bn2.weight
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_w    mapped name: layer3.10.conv2.weight
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_b    mapped name: layer3.10.conv3.bias
2024-04-12 19:36:13,649 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_b mapped name: layer3.10.bn3.bias
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_s mapped name: layer3.10.bn3.weight
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_w    mapped name: layer3.10.conv3.weight
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_b    mapped name: layer3.11.conv1.bias
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_b mapped name: layer3.11.bn1.bias
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_s mapped name: layer3.11.bn1.weight
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_w    mapped name: layer3.11.conv1.weight
2024-04-12 19:36:13,650 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_b    mapped name: layer3.11.conv2.bias
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_b mapped name: layer3.11.bn2.bias
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_s mapped name: layer3.11.bn2.weight
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_w    mapped name: layer3.11.conv2.weight
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_b    mapped name: layer3.11.conv3.bias
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_b mapped name: layer3.11.bn3.bias
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_s mapped name: layer3.11.bn3.weight
2024-04-12 19:36:13,651 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_w    mapped name: layer3.11.conv3.weight
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_b    mapped name: layer3.12.conv1.bias
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_b mapped name: layer3.12.bn1.bias
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_s mapped name: layer3.12.bn1.weight
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_w    mapped name: layer3.12.conv1.weight
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_b    mapped name: layer3.12.conv2.bias
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_b mapped name: layer3.12.bn2.bias
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_s mapped name: layer3.12.bn2.weight
2024-04-12 19:36:13,652 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_w    mapped name: layer3.12.conv2.weight
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_b    mapped name: layer3.12.conv3.bias
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_b mapped name: layer3.12.bn3.bias
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_s mapped name: layer3.12.bn3.weight
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_w    mapped name: layer3.12.conv3.weight
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_b    mapped name: layer3.13.conv1.bias
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_b mapped name: layer3.13.bn1.bias
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_s mapped name: layer3.13.bn1.weight
2024-04-12 19:36:13,653 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_w    mapped name: layer3.13.conv1.weight
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_b    mapped name: layer3.13.conv2.bias
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_b mapped name: layer3.13.bn2.bias
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_s mapped name: layer3.13.bn2.weight
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_w    mapped name: layer3.13.conv2.weight
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_b    mapped name: layer3.13.conv3.bias
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_b mapped name: layer3.13.bn3.bias
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_s mapped name: layer3.13.bn3.weight
2024-04-12 19:36:13,654 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_w    mapped name: layer3.13.conv3.weight
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_b    mapped name: layer3.14.conv1.bias
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_b mapped name: layer3.14.bn1.bias
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_s mapped name: layer3.14.bn1.weight
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_w    mapped name: layer3.14.conv1.weight
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_b    mapped name: layer3.14.conv2.bias
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_b mapped name: layer3.14.bn2.bias
2024-04-12 19:36:13,655 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_s mapped name: layer3.14.bn2.weight
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_w    mapped name: layer3.14.conv2.weight
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_b    mapped name: layer3.14.conv3.bias
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_b mapped name: layer3.14.bn3.bias
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_s mapped name: layer3.14.bn3.weight
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_w    mapped name: layer3.14.conv3.weight
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_b    mapped name: layer3.15.conv1.bias
2024-04-12 19:36:13,656 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_b mapped name: layer3.15.bn1.bias
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_s mapped name: layer3.15.bn1.weight
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_w    mapped name: layer3.15.conv1.weight
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_b    mapped name: layer3.15.conv2.bias
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_b mapped name: layer3.15.bn2.bias
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_s mapped name: layer3.15.bn2.weight
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_w    mapped name: layer3.15.conv2.weight
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_b    mapped name: layer3.15.conv3.bias
2024-04-12 19:36:13,657 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_b mapped name: layer3.15.bn3.bias
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_s mapped name: layer3.15.bn3.weight
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_w    mapped name: layer3.15.conv3.weight
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_b    mapped name: layer3.16.conv1.bias
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_b mapped name: layer3.16.bn1.bias
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_s mapped name: layer3.16.bn1.weight
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_w    mapped name: layer3.16.conv1.weight
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_b    mapped name: layer3.16.conv2.bias
2024-04-12 19:36:13,658 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_b mapped name: layer3.16.bn2.bias
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_s mapped name: layer3.16.bn2.weight
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_w    mapped name: layer3.16.conv2.weight
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_b    mapped name: layer3.16.conv3.bias
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_b mapped name: layer3.16.bn3.bias
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_s mapped name: layer3.16.bn3.weight
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_w    mapped name: layer3.16.conv3.weight
2024-04-12 19:36:13,659 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_b    mapped name: layer3.17.conv1.bias
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_b mapped name: layer3.17.bn1.bias
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_s mapped name: layer3.17.bn1.weight
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_w    mapped name: layer3.17.conv1.weight
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_b    mapped name: layer3.17.conv2.bias
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_b mapped name: layer3.17.bn2.bias
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_s mapped name: layer3.17.bn2.weight
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_w    mapped name: layer3.17.conv2.weight
2024-04-12 19:36:13,660 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_b    mapped name: layer3.17.conv3.bias
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_b mapped name: layer3.17.bn3.bias
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_s mapped name: layer3.17.bn3.weight
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_w    mapped name: layer3.17.conv3.weight
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_b    mapped name: layer3.18.conv1.bias
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_b mapped name: layer3.18.bn1.bias
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_s mapped name: layer3.18.bn1.weight
2024-04-12 19:36:13,661 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_w    mapped name: layer3.18.conv1.weight
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_b    mapped name: layer3.18.conv2.bias
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_b mapped name: layer3.18.bn2.bias
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_s mapped name: layer3.18.bn2.weight
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_w    mapped name: layer3.18.conv2.weight
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_b    mapped name: layer3.18.conv3.bias
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_b mapped name: layer3.18.bn3.bias
2024-04-12 19:36:13,662 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_s mapped name: layer3.18.bn3.weight
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_w    mapped name: layer3.18.conv3.weight
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_b    mapped name: layer3.19.conv1.bias
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_b mapped name: layer3.19.bn1.bias
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_s mapped name: layer3.19.bn1.weight
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_w    mapped name: layer3.19.conv1.weight
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_b    mapped name: layer3.19.conv2.bias
2024-04-12 19:36:13,663 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_b mapped name: layer3.19.bn2.bias
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_s mapped name: layer3.19.bn2.weight
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_w    mapped name: layer3.19.conv2.weight
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_b    mapped name: layer3.19.conv3.bias
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_b mapped name: layer3.19.bn3.bias
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_s mapped name: layer3.19.bn3.weight
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_w    mapped name: layer3.19.conv3.weight
2024-04-12 19:36:13,664 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b     mapped name: layer3.1.conv1.bias
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b  mapped name: layer3.1.bn1.bias
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s  mapped name: layer3.1.bn1.weight
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w     mapped name: layer3.1.conv1.weight
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b     mapped name: layer3.1.conv2.bias
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b  mapped name: layer3.1.bn2.bias
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s  mapped name: layer3.1.bn2.weight
2024-04-12 19:36:13,665 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w     mapped name: layer3.1.conv2.weight
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b     mapped name: layer3.1.conv3.bias
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b  mapped name: layer3.1.bn3.bias
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s  mapped name: layer3.1.bn3.weight
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w     mapped name: layer3.1.conv3.weight
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_b    mapped name: layer3.20.conv1.bias
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_b mapped name: layer3.20.bn1.bias
2024-04-12 19:36:13,666 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_s mapped name: layer3.20.bn1.weight
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_w    mapped name: layer3.20.conv1.weight
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_b    mapped name: layer3.20.conv2.bias
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_b mapped name: layer3.20.bn2.bias
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_s mapped name: layer3.20.bn2.weight
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_w    mapped name: layer3.20.conv2.weight
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_b    mapped name: layer3.20.conv3.bias
2024-04-12 19:36:13,667 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_b mapped name: layer3.20.bn3.bias
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_s mapped name: layer3.20.bn3.weight
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_w    mapped name: layer3.20.conv3.weight
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_b    mapped name: layer3.21.conv1.bias
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_b mapped name: layer3.21.bn1.bias
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_s mapped name: layer3.21.bn1.weight
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_w    mapped name: layer3.21.conv1.weight
2024-04-12 19:36:13,668 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_b    mapped name: layer3.21.conv2.bias
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_b mapped name: layer3.21.bn2.bias
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_s mapped name: layer3.21.bn2.weight
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_w    mapped name: layer3.21.conv2.weight
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_b    mapped name: layer3.21.conv3.bias
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_b mapped name: layer3.21.bn3.bias
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_s mapped name: layer3.21.bn3.weight
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_w    mapped name: layer3.21.conv3.weight
2024-04-12 19:36:13,669 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_b    mapped name: layer3.22.conv1.bias
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_b mapped name: layer3.22.bn1.bias
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_s mapped name: layer3.22.bn1.weight
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_w    mapped name: layer3.22.conv1.weight
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_b    mapped name: layer3.22.conv2.bias
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_b mapped name: layer3.22.bn2.bias
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_s mapped name: layer3.22.bn2.weight
2024-04-12 19:36:13,670 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_w    mapped name: layer3.22.conv2.weight
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_b    mapped name: layer3.22.conv3.bias
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_b mapped name: layer3.22.bn3.bias
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_s mapped name: layer3.22.bn3.weight
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_w    mapped name: layer3.22.conv3.weight
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b     mapped name: layer3.2.conv1.bias
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b  mapped name: layer3.2.bn1.bias
2024-04-12 19:36:13,671 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s  mapped name: layer3.2.bn1.weight
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w     mapped name: layer3.2.conv1.weight
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b     mapped name: layer3.2.conv2.bias
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b  mapped name: layer3.2.bn2.bias
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s  mapped name: layer3.2.bn2.weight
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w     mapped name: layer3.2.conv2.weight
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b     mapped name: layer3.2.conv3.bias
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b  mapped name: layer3.2.bn3.bias
2024-04-12 19:36:13,672 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s  mapped name: layer3.2.bn3.weight
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w     mapped name: layer3.2.conv3.weight
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b     mapped name: layer3.3.conv1.bias
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b  mapped name: layer3.3.bn1.bias
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s  mapped name: layer3.3.bn1.weight
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w     mapped name: layer3.3.conv1.weight
2024-04-12 19:36:13,673 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b     mapped name: layer3.3.conv2.bias
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b  mapped name: layer3.3.bn2.bias
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s  mapped name: layer3.3.bn2.weight
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w     mapped name: layer3.3.conv2.weight
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b     mapped name: layer3.3.conv3.bias
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b  mapped name: layer3.3.bn3.bias
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s  mapped name: layer3.3.bn3.weight
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w     mapped name: layer3.3.conv3.weight
2024-04-12 19:36:13,674 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b     mapped name: layer3.4.conv1.bias
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b  mapped name: layer3.4.bn1.bias
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s  mapped name: layer3.4.bn1.weight
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w     mapped name: layer3.4.conv1.weight
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b     mapped name: layer3.4.conv2.bias
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b  mapped name: layer3.4.bn2.bias
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s  mapped name: layer3.4.bn2.weight
2024-04-12 19:36:13,675 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w     mapped name: layer3.4.conv2.weight
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b     mapped name: layer3.4.conv3.bias
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b  mapped name: layer3.4.bn3.bias
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s  mapped name: layer3.4.bn3.weight
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w     mapped name: layer3.4.conv3.weight
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b     mapped name: layer3.5.conv1.bias
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b  mapped name: layer3.5.bn1.bias
2024-04-12 19:36:13,676 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s  mapped name: layer3.5.bn1.weight
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w     mapped name: layer3.5.conv1.weight
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b     mapped name: layer3.5.conv2.bias
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b  mapped name: layer3.5.bn2.bias
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s  mapped name: layer3.5.bn2.weight
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w     mapped name: layer3.5.conv2.weight
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b     mapped name: layer3.5.conv3.bias
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b  mapped name: layer3.5.bn3.bias
2024-04-12 19:36:13,677 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s  mapped name: layer3.5.bn3.weight
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w     mapped name: layer3.5.conv3.weight
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_b     mapped name: layer3.6.conv1.bias
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_b  mapped name: layer3.6.bn1.bias
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_s  mapped name: layer3.6.bn1.weight
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_w     mapped name: layer3.6.conv1.weight
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_b     mapped name: layer3.6.conv2.bias
2024-04-12 19:36:13,678 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_b  mapped name: layer3.6.bn2.bias
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_s  mapped name: layer3.6.bn2.weight
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_w     mapped name: layer3.6.conv2.weight
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_b     mapped name: layer3.6.conv3.bias
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_b  mapped name: layer3.6.bn3.bias
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_s  mapped name: layer3.6.bn3.weight
2024-04-12 19:36:13,679 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_w     mapped name: layer3.6.conv3.weight
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_b     mapped name: layer3.7.conv1.bias
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_b  mapped name: layer3.7.bn1.bias
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_s  mapped name: layer3.7.bn1.weight
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_w     mapped name: layer3.7.conv1.weight
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_b     mapped name: layer3.7.conv2.bias
2024-04-12 19:36:13,680 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_b  mapped name: layer3.7.bn2.bias
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_s  mapped name: layer3.7.bn2.weight
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_w     mapped name: layer3.7.conv2.weight
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_b     mapped name: layer3.7.conv3.bias
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_b  mapped name: layer3.7.bn3.bias
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_s  mapped name: layer3.7.bn3.weight
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_w     mapped name: layer3.7.conv3.weight
2024-04-12 19:36:13,681 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_b     mapped name: layer3.8.conv1.bias
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_b  mapped name: layer3.8.bn1.bias
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_s  mapped name: layer3.8.bn1.weight
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_w     mapped name: layer3.8.conv1.weight
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_b     mapped name: layer3.8.conv2.bias
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_b  mapped name: layer3.8.bn2.bias
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_s  mapped name: layer3.8.bn2.weight
2024-04-12 19:36:13,682 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_w     mapped name: layer3.8.conv2.weight
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_b     mapped name: layer3.8.conv3.bias
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_b  mapped name: layer3.8.bn3.bias
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_s  mapped name: layer3.8.bn3.weight
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_w     mapped name: layer3.8.conv3.weight
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_b     mapped name: layer3.9.conv1.bias
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_b  mapped name: layer3.9.bn1.bias
2024-04-12 19:36:13,683 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_s  mapped name: layer3.9.bn1.weight
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_w     mapped name: layer3.9.conv1.weight
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_b     mapped name: layer3.9.conv2.bias
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_b  mapped name: layer3.9.bn2.bias
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_s  mapped name: layer3.9.bn2.weight
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_w     mapped name: layer3.9.conv2.weight
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_b     mapped name: layer3.9.conv3.bias
2024-04-12 19:36:13,684 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_b  mapped name: layer3.9.bn3.bias
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_s  mapped name: layer3.9.bn3.weight
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_w     mapped name: layer3.9.conv3.weight
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b      mapped name: layer4.0.downsample.0.bias
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b   mapped name: layer4.0.downsample.1.bias
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s   mapped name: layer4.0.downsample.1.weight
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w      mapped name: layer4.0.downsample.0.weight
2024-04-12 19:36:13,685 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b     mapped name: layer4.0.conv1.bias
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b  mapped name: layer4.0.bn1.bias
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s  mapped name: layer4.0.bn1.weight
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w     mapped name: layer4.0.conv1.weight
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b     mapped name: layer4.0.conv2.bias
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b  mapped name: layer4.0.bn2.bias
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s  mapped name: layer4.0.bn2.weight
2024-04-12 19:36:13,686 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w     mapped name: layer4.0.conv2.weight
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b     mapped name: layer4.0.conv3.bias
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b  mapped name: layer4.0.bn3.bias
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s  mapped name: layer4.0.bn3.weight
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w     mapped name: layer4.0.conv3.weight
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b     mapped name: layer4.1.conv1.bias
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b  mapped name: layer4.1.bn1.bias
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s  mapped name: layer4.1.bn1.weight
2024-04-12 19:36:13,687 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w     mapped name: layer4.1.conv1.weight
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b     mapped name: layer4.1.conv2.bias
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b  mapped name: layer4.1.bn2.bias
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s  mapped name: layer4.1.bn2.weight
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w     mapped name: layer4.1.conv2.weight
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b     mapped name: layer4.1.conv3.bias
2024-04-12 19:36:13,688 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b  mapped name: layer4.1.bn3.bias
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s  mapped name: layer4.1.bn3.weight
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w     mapped name: layer4.1.conv3.weight
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b     mapped name: layer4.2.conv1.bias
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b  mapped name: layer4.2.bn1.bias
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s  mapped name: layer4.2.bn1.weight
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w     mapped name: layer4.2.conv1.weight
2024-04-12 19:36:13,689 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b     mapped name: layer4.2.conv2.bias
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b  mapped name: layer4.2.bn2.bias
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s  mapped name: layer4.2.bn2.weight
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w     mapped name: layer4.2.conv2.weight
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b     mapped name: layer4.2.conv3.bias
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b  mapped name: layer4.2.bn3.bias
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s  mapped name: layer4.2.bn3.weight
2024-04-12 19:36:13,690 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w     mapped name: layer4.2.conv3.weight
2024-04-12 19:36:13,691 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b        mapped name: bn1.bias
2024-04-12 19:36:13,691 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s        mapped name: bn1.weight
2024-04-12 19:36:13,691 mega_core.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2024-04-12 19:36:15,452 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-12 19:36:16,240 mega_core.trainer INFO: Start training
2024-04-12 19:36:36,594 mega_core.trainer INFO: eta: 13:50:34  iter: 21  loss: 73.1664 (77.0576)  loss_classifier: 42.8965 (45.3687)  loss_box_reg: 1.8164 (3.9691)  loss_objectness: 6.5395 (8.3993)  loss_rpn_box_reg: 16.8136 (19.3204)  time: 0.9336 (1.0174)  data: 0.0119 (0.0824)  lr: 0.000003  max mem: 5764
2024-04-12 19:37:26,522 mega_core INFO: Using 1 GPUs
2024-04-12 19:37:26,522 mega_core INFO: Namespace(config_file='configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml', distributed=False, launcher='pytorch', local_rank=0, master_port='29999', motion_specific=False, opts=['OUTPUT_DIR', 'training_dir/test'], save_name='', skip_test=False)
2024-04-12 19:37:26,522 mega_core INFO: Collecting env info (might take some time)
2024-04-12 19:37:28,074 mega_core INFO: 
PyTorch version: 1.10.1+cu102
Is debug build: False
CUDA used to build PyTorch: 10.2
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.6 LTS (x86_64)
GCC version: (Ubuntu 6.4.0-17ubuntu1) 6.4.0 20180424
Clang version: Could not collect
CMake version: Could not collect
Libc version: glibc-2.31

Python version: 3.8.18 (default, Sep 11 2023, 13:40:15)  [GCC 11.2.0] (64-bit runtime)
Python platform: Linux-5.15.0-101-generic-x86_64-with-glibc2.17
Is CUDA available: True
CUDA runtime version: 10.1.243
GPU models and configuration: 
GPU 0: NVIDIA TITAN Xp COLLECTORS EDITION
GPU 1: NVIDIA TITAN Xp
GPU 2: NVIDIA TITAN Xp COLLECTORS EDITION

Nvidia driver version: 535.161.07
cuDNN version: Could not collect
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] mypy-extensions==1.0.0
[pip3] numpy==1.23.5
[pip3] torch==1.10.1+cu102
[pip3] torchaudio==0.10.1+cu102
[pip3] torchvision==0.11.2+cu102
[conda] numpy                     1.26.4                   pypi_0    pypi
        Pillow (8.3.2)
2024-04-12 19:37:28,074 mega_core INFO: Loaded configuration file configs/MEGA/vid_R_101_C4_MEGA_1x_UAVTOD.yaml
2024-04-12 19:37:28,075 mega_core INFO: 
MODEL:
  VID:
    METHOD: "mega"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: True  # local attention
        STAGE: 3  # local attention stages
    MEGA:
      MIN_OFFSET: -12
      MAX_OFFSET: 12
      ALL_FRAME_INTERVAL: 25
      KEY_FRAME_LOCATION: 12
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: True  # local attention
        PIXEL_ATTEND: False
      MEMORY:
        ENABLE: True  # long range memory
        SIZE: 25
      GLOBAL:
        ENABLE: True  # global attention
        RES_STAGE: 1
        SIZE: 10  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: False
        BOX_ATTEND: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
      MHA: False
      REF_NUM_GLOBAL: 2  # ref num in training phase
      MEMORY_MANAGEMENT_METRIC: "queue"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "none"  # once, twice, sequential, greedy, random
  META_ARCHITECTURE: "GeneralizedRCNNMEGA"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-C4"
  ROI_BOX_HEAD:
    FEATURE_EXTRACTOR: "MEGAFeatureExtractor"
    PREDICTOR: "FPNPredictor"
SOLVER:
  OPTIMIZER_TYPE: "adamw" #"adamw" "sgd"
  LR_SCHEDULER_TYPE: "step" # step or cosine
  BASE_LR: 0.0001 # 0.00001 # 0.001 for SGD
  BIAS_LR_FACTOR: 1.0
  BACKBONE_MULTIPLIER: 0.1
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  STEPS: (24000, 32000, 40000) # (240000, ) for aug # (80000, ) for COCO pretrained
  MAX_ITER: 49000 # 360000 for aug # 120000 for COCO pretrained
  WARMUP_ITERS: 7857 # 18000
  TEST_PERIOD: 40
  CHECKPOINT_PERIOD: 5000
  ACCUMULATION_STEPS: 1  # batch size multiplier
  BATCH_REUSE_STEPS: 1
DATASETS:
  TRAIN: ("VID_UAVTOD_train_all",)
  TEST: ("VID_UAVTOD_val",) # ("VID_val_videos",) # ("YouTube_Objects",)
# INPUT:
#   PIXEL_MEAN: [ 123.675, 116.280, 103.530 ] # RGB
#   PIXEL_STD: [ 58.395, 57.120, 57.375 ]
#   TO_BGR255: False # pretrained torchvision weight use RGB format.
#   TRANSFORM: True
#   INFER_BATCH: 8 # must be same with MAX_OFFSET + 1
2024-04-12 19:37:28,077 mega_core INFO: Running with config:
AMP_VERBOSE: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  NUM_WORKERS: 1
  PIN_MEMORY: False
  SIZE_DIVISIBILITY: 0
DATASETS:
  TEST: ('VID_UAVTOD_val',)
  TRAIN: ('VID_UAVTOD_train_all',)
DTYPE: float32
INPUT:
  BRIGHTNESS: 0.166
  CONTRAST: 0.5
  HORIZONTAL_FLIP_PROB_TRAIN: 0.5
  HUE: 0.5
  INFER_BATCH: 1
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (600,)
  PIXEL_MEAN: [102.9801, 115.9465, 122.7717]
  PIXEL_STD: [1.0, 1.0, 1.0]
  RANROM_CROP_MAX_RATIO_TRAIN: 2.0
  RANROM_CROP_MAX_SIZE_TRAIN: 1.0
  RANROM_CROP_MIN_SIZE_TRAIN: 0.3
  RANROM_CROP_PROB_TRAIN: 0.5
  RANROM_PAD_PROB_TRAIN: 0.5
  RANROM_PAD_SIZE_TRAIN: 1.0
  SATURATION: 0.5
  TO_BGR255: True
  TRANSFORM: False
  VERTICAL_FLIP_PROB_TRAIN: 0.0
MODEL:
  BACKBONE:
    CONV_BODY: R-101-C4
    FREEZE_CONV_BODY_AT: 2
  CLS_AGNOSTIC_BBOX_REG: False
  DEVICE: cuda
  FBNET:
    ARCH: default
    ARCH_DEF: 
    BN_TYPE: bn
    DET_HEAD_BLOCKS: []
    DET_HEAD_LAST_SCALE: 1.0
    DET_HEAD_STRIDE: 0
    DW_CONV_SKIP_BN: True
    DW_CONV_SKIP_RELU: True
    KPTS_HEAD_BLOCKS: []
    KPTS_HEAD_LAST_SCALE: 0.0
    KPTS_HEAD_STRIDE: 0
    MASK_HEAD_BLOCKS: []
    MASK_HEAD_LAST_SCALE: 0.0
    MASK_HEAD_STRIDE: 0
    RPN_BN_TYPE: 
    RPN_HEAD_BLOCKS: 0
    SCALE_FACTOR: 1.0
    WIDTH_DIVISOR: 1
  FPN:
    USE_GN: False
    USE_RELU: False
  GROUP_NORM:
    DIM_PER_GP: -1
    EPSILON: 1e-05
    NUM_GROUPS: 32
  KEYPOINT_ON: False
  MASK_ON: False
  META_ARCHITECTURE: GeneralizedRCNNMEGA
  RESNETS:
    BACKBONE_OUT_CHANNELS: 1024
    DEFORMABLE_GROUPS: 1
    NUM_GROUPS: 1
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 2
    STAGE_WITH_DCN: (False, False, False, False)
    STEM_FUNC: StemWithFixedBatchNorm
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    TRANS_FUNC: BottleneckWithFixedBatchNorm
    WIDTH_PER_GROUP: 64
    WITH_MODULATED_DCN: False
  RETINANET:
    ANCHOR_SIZES: (32, 64, 128, 256, 512)
    ANCHOR_STRIDES: (8, 16, 32, 64, 128)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BBOX_REG_BETA: 0.11
    BBOX_REG_WEIGHT: 4.0
    BG_IOU_THRESHOLD: 0.4
    FG_IOU_THRESHOLD: 0.5
    INFERENCE_TH: 0.05
    LOSS_ALPHA: 0.25
    LOSS_GAMMA: 2.0
    NMS_TH: 0.4
    NUM_CLASSES: 81
    NUM_CONVS: 4
    OCTAVE: 2.0
    PRE_NMS_TOP_N: 1000
    PRIOR_PROB: 0.01
    SCALES_PER_OCTAVE: 3
    STRADDLE_THRESH: 0
    USE_C5: True
  RETINANET_ON: False
  ROI_BOX_HEAD:
    CONV_HEAD_DIM: 256
    DILATION: 1
    FEATURE_EXTRACTOR: MEGAFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 31
    NUM_STACKED_CONVS: 4
    POOLER_RESOLUTION: 7
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: FPNPredictor
    USE_GN: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    BG_IOU_THRESHOLD: 0.5
    DETECTIONS_PER_IMG: 300
    FG_IOU_THRESHOLD: 0.5
    NMS: 0.5
    POSITIVE_FRACTION: 0.25
    SCORE_THRESH: 0.001
    USE_FPN: False
  ROI_KEYPOINT_HEAD:
    CONV_LAYERS: (512, 512, 512, 512, 512, 512, 512, 512)
    FEATURE_EXTRACTOR: KeypointRCNNFeatureExtractor
    MLP_HEAD_DIM: 1024
    NUM_CLASSES: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    PREDICTOR: KeypointRCNNPredictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
  ROI_MASK_HEAD:
    CONV_LAYERS: (256, 256, 256, 256)
    DILATION: 1
    FEATURE_EXTRACTOR: ResNet50Conv5ROIFeatureExtractor
    MLP_HEAD_DIM: 1024
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_SCALES: (0.0625,)
    POSTPROCESS_MASKS: False
    POSTPROCESS_MASKS_THRESHOLD: 0.5
    PREDICTOR: MaskRCNNC4Predictor
    RESOLUTION: 14
    SHARE_BOX_FEATURE_EXTRACTOR: True
    USE_GN: False
  RPN:
    ANCHOR_SIZES: (64, 128, 256, 512)
    ANCHOR_STRIDE: (16,)
    ASPECT_RATIOS: (0.5, 1.0, 2.0)
    BATCH_SIZE_PER_IMAGE: 256
    BG_IOU_THRESHOLD: 0.3
    FG_IOU_THRESHOLD: 0.7
    FPN_POST_NMS_PER_BATCH: True
    FPN_POST_NMS_TOP_N_TEST: 2000
    FPN_POST_NMS_TOP_N_TRAIN: 2000
    MIN_SIZE: 0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOP_N_TEST: 300
    POST_NMS_TOP_N_TRAIN: 300
    PRE_NMS_TOP_N_TEST: 6000
    PRE_NMS_TOP_N_TRAIN: 6000
    RPN_HEAD: SingleConvRPNHead
    STRADDLE_THRESH: 0
    USE_FPN: False
  RPN_ONLY: False
  VID:
    DFF:
      MAX_OFFSET: 0
      MIN_OFFSET: -9
    ENABLE: True
    FGFA:
      ALL_FRAME_INTERVAL: 19
      KEY_FRAME_LOCATION: 9
      MAX_OFFSET: 9
      MIN_OFFSET: -9
      REF_NUM: 2
    FLOWNET_WEIGHT: models/flownet.ckpt
    IGNORE: False
    MEGA:
      ALL_FRAME_INTERVAL: 25
      GLOBAL:
        BOX_ATTEND: True
        ENABLE: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
        RES_STAGE: 1
        SHUFFLE: True
        SIZE: 10
        STOP_UPDATE_AFTER_INIT_TEST: False
      KEY_FRAME_LOCATION: 12
      LOCAL:
        ENABLE: True
        PIXEL_ATTEND: False
      MAX_OFFSET: 12
      MEMORY:
        ENABLE: True
        SIZE: 25
      MEMORY_MANAGEMENT_METRIC: queue
      MEMORY_MANAGEMENT_SIZE_PIXEL_TEST: 1000
      MEMORY_MANAGEMENT_SIZE_PIXEL_TRAIN: 3000
      MEMORY_MANAGEMENT_SIZE_TEST: 750
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_TYPE: none
      MHA: False
      MIN_OFFSET: -12
      RATIO: 0.2
      REF_NUM_GLOBAL: 2
      REF_NUM_LOCAL: 2
      REF_NUM_MEM: 3
      SHUFFLED_CUR_TEST: False
    METHOD: mega
    RDN:
      ALL_FRAME_INTERVAL: 37
      KEY_FRAME_LOCATION: 18
      MAX_OFFSET: 18
      MIN_OFFSET: -18
      RATIO: 0.2
      REF_NUM: 2
    ROI_BOX_HEAD:
      ATTENTION:
        ADVANCED_STAGE: 0
        EMBED_DIM: 64
        ENABLE: True
        GROUP: 16
        STAGE: 3
      REDUCE_CHANNEL: False
    RPN:
      REF_POST_NMS_TOP_N: 75
      REF_PRE_NMS_TOP_N: 6000
  WEIGHT: catalog://ImageNetPretrained/MSRA/R-101
OUTPUT_DIR: training_dir/test
PATHS_CATALOG: /data1/jiahaoguo/DiffusionVID/mega_core/config/paths_catalog.py
SOLVER:
  ACCUMULATION_STEPS: 1
  BACKBONE_MULTIPLIER: 0.1
  BASE_LR: 0.0001
  BATCH_REUSE_STEPS: 1
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0
    ENABLED: False
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_TYPE: step
  MAX_ITER: 49000
  MOMENTUM: 0.9
  OPTIMIZER_TYPE: adamw
  STEPS: (24000, 32000, 40000)
  TEST_PERIOD: 40
  WARMUP_FACTOR: 0.3333333333333333
  WARMUP_ITERS: 7857
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
TENSORBOARD: True
TEST:
  BBOX_AUG:
    ENABLED: False
    H_FLIP: False
    MAX_SIZE: 4000
    SCALES: ()
    SCALE_H_FLIP: False
  DETECTIONS_PER_IMG: 300
  EXPECTED_RESULTS: []
  EXPECTED_RESULTS_SIGMA_TOL: 4
  IMS_PER_BATCH: 1
  SEQ_NMS: False
2024-04-12 19:37:28,077 mega_core INFO: Saving config into: training_dir/test/config.yml
2024-04-12 19:37:34,150 mega_core.utils.checkpoint INFO: Loading checkpoint from catalog://ImageNetPretrained/MSRA/R-101
2024-04-12 19:37:34,152 mega_core.utils.checkpoint INFO: catalog://ImageNetPretrained/MSRA/R-101 points to https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl
2024-04-12 19:37:34,153 mega_core.utils.checkpoint INFO: url https://dl.fbaipublicfiles.com/detectron/ImageNetPretrained/MSRA/R-101.pkl cached in /home/jiahaoguo/.torch/models/R-101.pkl
2024-04-12 19:37:34,292 mega_core.utils.c2_model_loading INFO: Remapping C2 weights
2024-04-12 19:37:34,292 mega_core.utils.c2_model_loading INFO: C2 name: conv1_b               mapped name: conv1.bias
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: conv1_w               mapped name: conv1.weight
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_b              mapped name: fc1000.bias
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: fc1000_w              mapped name: fc1000.weight
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_b      mapped name: layer1.0.downsample.0.bias
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_b   mapped name: layer1.0.downsample.1.bias
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_bn_s   mapped name: layer1.0.downsample.1.weight
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch1_w      mapped name: layer1.0.downsample.0.weight
2024-04-12 19:37:34,293 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_b     mapped name: layer1.0.conv1.bias
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_b  mapped name: layer1.0.bn1.bias
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_bn_s  mapped name: layer1.0.bn1.weight
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2a_w     mapped name: layer1.0.conv1.weight
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_b     mapped name: layer1.0.conv2.bias
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_b  mapped name: layer1.0.bn2.bias
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_bn_s  mapped name: layer1.0.bn2.weight
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2b_w     mapped name: layer1.0.conv2.weight
2024-04-12 19:37:34,294 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_b     mapped name: layer1.0.conv3.bias
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_b  mapped name: layer1.0.bn3.bias
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_bn_s  mapped name: layer1.0.bn3.weight
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_0_branch2c_w     mapped name: layer1.0.conv3.weight
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_b     mapped name: layer1.1.conv1.bias
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_b  mapped name: layer1.1.bn1.bias
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_bn_s  mapped name: layer1.1.bn1.weight
2024-04-12 19:37:34,295 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2a_w     mapped name: layer1.1.conv1.weight
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_b     mapped name: layer1.1.conv2.bias
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_b  mapped name: layer1.1.bn2.bias
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_bn_s  mapped name: layer1.1.bn2.weight
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2b_w     mapped name: layer1.1.conv2.weight
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_b     mapped name: layer1.1.conv3.bias
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_b  mapped name: layer1.1.bn3.bias
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_bn_s  mapped name: layer1.1.bn3.weight
2024-04-12 19:37:34,296 mega_core.utils.c2_model_loading INFO: C2 name: res2_1_branch2c_w     mapped name: layer1.1.conv3.weight
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_b     mapped name: layer1.2.conv1.bias
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_b  mapped name: layer1.2.bn1.bias
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_bn_s  mapped name: layer1.2.bn1.weight
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2a_w     mapped name: layer1.2.conv1.weight
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_b     mapped name: layer1.2.conv2.bias
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_b  mapped name: layer1.2.bn2.bias
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_bn_s  mapped name: layer1.2.bn2.weight
2024-04-12 19:37:34,297 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2b_w     mapped name: layer1.2.conv2.weight
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_b     mapped name: layer1.2.conv3.bias
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_b  mapped name: layer1.2.bn3.bias
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_bn_s  mapped name: layer1.2.bn3.weight
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res2_2_branch2c_w     mapped name: layer1.2.conv3.weight
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_b      mapped name: layer2.0.downsample.0.bias
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_b   mapped name: layer2.0.downsample.1.bias
2024-04-12 19:37:34,298 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_bn_s   mapped name: layer2.0.downsample.1.weight
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch1_w      mapped name: layer2.0.downsample.0.weight
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_b     mapped name: layer2.0.conv1.bias
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_b  mapped name: layer2.0.bn1.bias
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_bn_s  mapped name: layer2.0.bn1.weight
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2a_w     mapped name: layer2.0.conv1.weight
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_b     mapped name: layer2.0.conv2.bias
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_b  mapped name: layer2.0.bn2.bias
2024-04-12 19:37:34,299 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_bn_s  mapped name: layer2.0.bn2.weight
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2b_w     mapped name: layer2.0.conv2.weight
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_b     mapped name: layer2.0.conv3.bias
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_b  mapped name: layer2.0.bn3.bias
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_bn_s  mapped name: layer2.0.bn3.weight
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_0_branch2c_w     mapped name: layer2.0.conv3.weight
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_b     mapped name: layer2.1.conv1.bias
2024-04-12 19:37:34,300 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_b  mapped name: layer2.1.bn1.bias
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_bn_s  mapped name: layer2.1.bn1.weight
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2a_w     mapped name: layer2.1.conv1.weight
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_b     mapped name: layer2.1.conv2.bias
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_b  mapped name: layer2.1.bn2.bias
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_bn_s  mapped name: layer2.1.bn2.weight
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2b_w     mapped name: layer2.1.conv2.weight
2024-04-12 19:37:34,301 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_b     mapped name: layer2.1.conv3.bias
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_b  mapped name: layer2.1.bn3.bias
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_bn_s  mapped name: layer2.1.bn3.weight
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_1_branch2c_w     mapped name: layer2.1.conv3.weight
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_b     mapped name: layer2.2.conv1.bias
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_b  mapped name: layer2.2.bn1.bias
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_bn_s  mapped name: layer2.2.bn1.weight
2024-04-12 19:37:34,302 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2a_w     mapped name: layer2.2.conv1.weight
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_b     mapped name: layer2.2.conv2.bias
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_b  mapped name: layer2.2.bn2.bias
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_bn_s  mapped name: layer2.2.bn2.weight
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2b_w     mapped name: layer2.2.conv2.weight
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_b     mapped name: layer2.2.conv3.bias
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_b  mapped name: layer2.2.bn3.bias
2024-04-12 19:37:34,303 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_bn_s  mapped name: layer2.2.bn3.weight
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_2_branch2c_w     mapped name: layer2.2.conv3.weight
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_b     mapped name: layer2.3.conv1.bias
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_b  mapped name: layer2.3.bn1.bias
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_bn_s  mapped name: layer2.3.bn1.weight
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2a_w     mapped name: layer2.3.conv1.weight
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_b     mapped name: layer2.3.conv2.bias
2024-04-12 19:37:34,304 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_b  mapped name: layer2.3.bn2.bias
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_bn_s  mapped name: layer2.3.bn2.weight
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2b_w     mapped name: layer2.3.conv2.weight
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_b     mapped name: layer2.3.conv3.bias
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_b  mapped name: layer2.3.bn3.bias
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_bn_s  mapped name: layer2.3.bn3.weight
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res3_3_branch2c_w     mapped name: layer2.3.conv3.weight
2024-04-12 19:37:34,305 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_b      mapped name: layer3.0.downsample.0.bias
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_b   mapped name: layer3.0.downsample.1.bias
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_bn_s   mapped name: layer3.0.downsample.1.weight
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch1_w      mapped name: layer3.0.downsample.0.weight
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_b     mapped name: layer3.0.conv1.bias
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_b  mapped name: layer3.0.bn1.bias
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_bn_s  mapped name: layer3.0.bn1.weight
2024-04-12 19:37:34,306 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2a_w     mapped name: layer3.0.conv1.weight
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_b     mapped name: layer3.0.conv2.bias
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_b  mapped name: layer3.0.bn2.bias
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_bn_s  mapped name: layer3.0.bn2.weight
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2b_w     mapped name: layer3.0.conv2.weight
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_b     mapped name: layer3.0.conv3.bias
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_b  mapped name: layer3.0.bn3.bias
2024-04-12 19:37:34,307 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_bn_s  mapped name: layer3.0.bn3.weight
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_0_branch2c_w     mapped name: layer3.0.conv3.weight
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_b    mapped name: layer3.10.conv1.bias
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_b mapped name: layer3.10.bn1.bias
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_bn_s mapped name: layer3.10.bn1.weight
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2a_w    mapped name: layer3.10.conv1.weight
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_b    mapped name: layer3.10.conv2.bias
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_b mapped name: layer3.10.bn2.bias
2024-04-12 19:37:34,308 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_bn_s mapped name: layer3.10.bn2.weight
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2b_w    mapped name: layer3.10.conv2.weight
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_b    mapped name: layer3.10.conv3.bias
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_b mapped name: layer3.10.bn3.bias
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_bn_s mapped name: layer3.10.bn3.weight
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_10_branch2c_w    mapped name: layer3.10.conv3.weight
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_b    mapped name: layer3.11.conv1.bias
2024-04-12 19:37:34,309 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_b mapped name: layer3.11.bn1.bias
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_bn_s mapped name: layer3.11.bn1.weight
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2a_w    mapped name: layer3.11.conv1.weight
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_b    mapped name: layer3.11.conv2.bias
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_b mapped name: layer3.11.bn2.bias
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_bn_s mapped name: layer3.11.bn2.weight
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2b_w    mapped name: layer3.11.conv2.weight
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_b    mapped name: layer3.11.conv3.bias
2024-04-12 19:37:34,310 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_b mapped name: layer3.11.bn3.bias
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_bn_s mapped name: layer3.11.bn3.weight
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_11_branch2c_w    mapped name: layer3.11.conv3.weight
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_b    mapped name: layer3.12.conv1.bias
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_b mapped name: layer3.12.bn1.bias
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_bn_s mapped name: layer3.12.bn1.weight
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2a_w    mapped name: layer3.12.conv1.weight
2024-04-12 19:37:34,311 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_b    mapped name: layer3.12.conv2.bias
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_b mapped name: layer3.12.bn2.bias
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_bn_s mapped name: layer3.12.bn2.weight
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2b_w    mapped name: layer3.12.conv2.weight
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_b    mapped name: layer3.12.conv3.bias
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_b mapped name: layer3.12.bn3.bias
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_bn_s mapped name: layer3.12.bn3.weight
2024-04-12 19:37:34,312 mega_core.utils.c2_model_loading INFO: C2 name: res4_12_branch2c_w    mapped name: layer3.12.conv3.weight
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_b    mapped name: layer3.13.conv1.bias
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_b mapped name: layer3.13.bn1.bias
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_bn_s mapped name: layer3.13.bn1.weight
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2a_w    mapped name: layer3.13.conv1.weight
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_b    mapped name: layer3.13.conv2.bias
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_b mapped name: layer3.13.bn2.bias
2024-04-12 19:37:34,313 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_bn_s mapped name: layer3.13.bn2.weight
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2b_w    mapped name: layer3.13.conv2.weight
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_b    mapped name: layer3.13.conv3.bias
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_b mapped name: layer3.13.bn3.bias
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_bn_s mapped name: layer3.13.bn3.weight
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_13_branch2c_w    mapped name: layer3.13.conv3.weight
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_b    mapped name: layer3.14.conv1.bias
2024-04-12 19:37:34,314 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_b mapped name: layer3.14.bn1.bias
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_bn_s mapped name: layer3.14.bn1.weight
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2a_w    mapped name: layer3.14.conv1.weight
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_b    mapped name: layer3.14.conv2.bias
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_b mapped name: layer3.14.bn2.bias
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_bn_s mapped name: layer3.14.bn2.weight
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2b_w    mapped name: layer3.14.conv2.weight
2024-04-12 19:37:34,315 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_b    mapped name: layer3.14.conv3.bias
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_b mapped name: layer3.14.bn3.bias
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_bn_s mapped name: layer3.14.bn3.weight
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_14_branch2c_w    mapped name: layer3.14.conv3.weight
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_b    mapped name: layer3.15.conv1.bias
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_b mapped name: layer3.15.bn1.bias
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_bn_s mapped name: layer3.15.bn1.weight
2024-04-12 19:37:34,316 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2a_w    mapped name: layer3.15.conv1.weight
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_b    mapped name: layer3.15.conv2.bias
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_b mapped name: layer3.15.bn2.bias
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_bn_s mapped name: layer3.15.bn2.weight
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2b_w    mapped name: layer3.15.conv2.weight
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_b    mapped name: layer3.15.conv3.bias
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_b mapped name: layer3.15.bn3.bias
2024-04-12 19:37:34,317 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_bn_s mapped name: layer3.15.bn3.weight
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_15_branch2c_w    mapped name: layer3.15.conv3.weight
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_b    mapped name: layer3.16.conv1.bias
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_b mapped name: layer3.16.bn1.bias
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_bn_s mapped name: layer3.16.bn1.weight
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2a_w    mapped name: layer3.16.conv1.weight
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_b    mapped name: layer3.16.conv2.bias
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_b mapped name: layer3.16.bn2.bias
2024-04-12 19:37:34,318 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_bn_s mapped name: layer3.16.bn2.weight
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2b_w    mapped name: layer3.16.conv2.weight
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_b    mapped name: layer3.16.conv3.bias
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_b mapped name: layer3.16.bn3.bias
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_bn_s mapped name: layer3.16.bn3.weight
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_16_branch2c_w    mapped name: layer3.16.conv3.weight
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_b    mapped name: layer3.17.conv1.bias
2024-04-12 19:37:34,319 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_b mapped name: layer3.17.bn1.bias
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_bn_s mapped name: layer3.17.bn1.weight
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2a_w    mapped name: layer3.17.conv1.weight
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_b    mapped name: layer3.17.conv2.bias
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_b mapped name: layer3.17.bn2.bias
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_bn_s mapped name: layer3.17.bn2.weight
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2b_w    mapped name: layer3.17.conv2.weight
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_b    mapped name: layer3.17.conv3.bias
2024-04-12 19:37:34,320 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_b mapped name: layer3.17.bn3.bias
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_bn_s mapped name: layer3.17.bn3.weight
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_17_branch2c_w    mapped name: layer3.17.conv3.weight
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_b    mapped name: layer3.18.conv1.bias
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_b mapped name: layer3.18.bn1.bias
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_bn_s mapped name: layer3.18.bn1.weight
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2a_w    mapped name: layer3.18.conv1.weight
2024-04-12 19:37:34,321 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_b    mapped name: layer3.18.conv2.bias
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_b mapped name: layer3.18.bn2.bias
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_bn_s mapped name: layer3.18.bn2.weight
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2b_w    mapped name: layer3.18.conv2.weight
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_b    mapped name: layer3.18.conv3.bias
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_b mapped name: layer3.18.bn3.bias
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_bn_s mapped name: layer3.18.bn3.weight
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_18_branch2c_w    mapped name: layer3.18.conv3.weight
2024-04-12 19:37:34,322 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_b    mapped name: layer3.19.conv1.bias
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_b mapped name: layer3.19.bn1.bias
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_bn_s mapped name: layer3.19.bn1.weight
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2a_w    mapped name: layer3.19.conv1.weight
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_b    mapped name: layer3.19.conv2.bias
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_b mapped name: layer3.19.bn2.bias
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_bn_s mapped name: layer3.19.bn2.weight
2024-04-12 19:37:34,323 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2b_w    mapped name: layer3.19.conv2.weight
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_b    mapped name: layer3.19.conv3.bias
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_b mapped name: layer3.19.bn3.bias
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_bn_s mapped name: layer3.19.bn3.weight
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_19_branch2c_w    mapped name: layer3.19.conv3.weight
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_b     mapped name: layer3.1.conv1.bias
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_b  mapped name: layer3.1.bn1.bias
2024-04-12 19:37:34,324 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_bn_s  mapped name: layer3.1.bn1.weight
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2a_w     mapped name: layer3.1.conv1.weight
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_b     mapped name: layer3.1.conv2.bias
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_b  mapped name: layer3.1.bn2.bias
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_bn_s  mapped name: layer3.1.bn2.weight
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2b_w     mapped name: layer3.1.conv2.weight
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_b     mapped name: layer3.1.conv3.bias
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_b  mapped name: layer3.1.bn3.bias
2024-04-12 19:37:34,325 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_bn_s  mapped name: layer3.1.bn3.weight
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_1_branch2c_w     mapped name: layer3.1.conv3.weight
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_b    mapped name: layer3.20.conv1.bias
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_b mapped name: layer3.20.bn1.bias
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_bn_s mapped name: layer3.20.bn1.weight
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2a_w    mapped name: layer3.20.conv1.weight
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_b    mapped name: layer3.20.conv2.bias
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_b mapped name: layer3.20.bn2.bias
2024-04-12 19:37:34,326 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_bn_s mapped name: layer3.20.bn2.weight
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2b_w    mapped name: layer3.20.conv2.weight
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_b    mapped name: layer3.20.conv3.bias
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_b mapped name: layer3.20.bn3.bias
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_bn_s mapped name: layer3.20.bn3.weight
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_20_branch2c_w    mapped name: layer3.20.conv3.weight
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_b    mapped name: layer3.21.conv1.bias
2024-04-12 19:37:34,327 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_b mapped name: layer3.21.bn1.bias
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_bn_s mapped name: layer3.21.bn1.weight
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2a_w    mapped name: layer3.21.conv1.weight
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_b    mapped name: layer3.21.conv2.bias
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_b mapped name: layer3.21.bn2.bias
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_bn_s mapped name: layer3.21.bn2.weight
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2b_w    mapped name: layer3.21.conv2.weight
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_b    mapped name: layer3.21.conv3.bias
2024-04-12 19:37:34,328 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_b mapped name: layer3.21.bn3.bias
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_bn_s mapped name: layer3.21.bn3.weight
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_21_branch2c_w    mapped name: layer3.21.conv3.weight
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_b    mapped name: layer3.22.conv1.bias
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_b mapped name: layer3.22.bn1.bias
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_bn_s mapped name: layer3.22.bn1.weight
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2a_w    mapped name: layer3.22.conv1.weight
2024-04-12 19:37:34,329 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_b    mapped name: layer3.22.conv2.bias
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_b mapped name: layer3.22.bn2.bias
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_bn_s mapped name: layer3.22.bn2.weight
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2b_w    mapped name: layer3.22.conv2.weight
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_b    mapped name: layer3.22.conv3.bias
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_b mapped name: layer3.22.bn3.bias
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_bn_s mapped name: layer3.22.bn3.weight
2024-04-12 19:37:34,330 mega_core.utils.c2_model_loading INFO: C2 name: res4_22_branch2c_w    mapped name: layer3.22.conv3.weight
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_b     mapped name: layer3.2.conv1.bias
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_b  mapped name: layer3.2.bn1.bias
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_bn_s  mapped name: layer3.2.bn1.weight
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2a_w     mapped name: layer3.2.conv1.weight
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_b     mapped name: layer3.2.conv2.bias
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_b  mapped name: layer3.2.bn2.bias
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_bn_s  mapped name: layer3.2.bn2.weight
2024-04-12 19:37:34,331 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2b_w     mapped name: layer3.2.conv2.weight
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_b     mapped name: layer3.2.conv3.bias
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_b  mapped name: layer3.2.bn3.bias
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_bn_s  mapped name: layer3.2.bn3.weight
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_2_branch2c_w     mapped name: layer3.2.conv3.weight
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_b     mapped name: layer3.3.conv1.bias
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_b  mapped name: layer3.3.bn1.bias
2024-04-12 19:37:34,332 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_bn_s  mapped name: layer3.3.bn1.weight
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2a_w     mapped name: layer3.3.conv1.weight
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_b     mapped name: layer3.3.conv2.bias
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_b  mapped name: layer3.3.bn2.bias
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_bn_s  mapped name: layer3.3.bn2.weight
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2b_w     mapped name: layer3.3.conv2.weight
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_b     mapped name: layer3.3.conv3.bias
2024-04-12 19:37:34,333 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_b  mapped name: layer3.3.bn3.bias
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_bn_s  mapped name: layer3.3.bn3.weight
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_3_branch2c_w     mapped name: layer3.3.conv3.weight
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_b     mapped name: layer3.4.conv1.bias
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_b  mapped name: layer3.4.bn1.bias
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_bn_s  mapped name: layer3.4.bn1.weight
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2a_w     mapped name: layer3.4.conv1.weight
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_b     mapped name: layer3.4.conv2.bias
2024-04-12 19:37:34,334 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_b  mapped name: layer3.4.bn2.bias
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_bn_s  mapped name: layer3.4.bn2.weight
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2b_w     mapped name: layer3.4.conv2.weight
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_b     mapped name: layer3.4.conv3.bias
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_b  mapped name: layer3.4.bn3.bias
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_bn_s  mapped name: layer3.4.bn3.weight
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_4_branch2c_w     mapped name: layer3.4.conv3.weight
2024-04-12 19:37:34,335 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_b     mapped name: layer3.5.conv1.bias
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_b  mapped name: layer3.5.bn1.bias
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_bn_s  mapped name: layer3.5.bn1.weight
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2a_w     mapped name: layer3.5.conv1.weight
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_b     mapped name: layer3.5.conv2.bias
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_b  mapped name: layer3.5.bn2.bias
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_bn_s  mapped name: layer3.5.bn2.weight
2024-04-12 19:37:34,336 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2b_w     mapped name: layer3.5.conv2.weight
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_b     mapped name: layer3.5.conv3.bias
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_b  mapped name: layer3.5.bn3.bias
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_bn_s  mapped name: layer3.5.bn3.weight
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_5_branch2c_w     mapped name: layer3.5.conv3.weight
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_b     mapped name: layer3.6.conv1.bias
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_b  mapped name: layer3.6.bn1.bias
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_bn_s  mapped name: layer3.6.bn1.weight
2024-04-12 19:37:34,337 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2a_w     mapped name: layer3.6.conv1.weight
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_b     mapped name: layer3.6.conv2.bias
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_b  mapped name: layer3.6.bn2.bias
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_bn_s  mapped name: layer3.6.bn2.weight
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2b_w     mapped name: layer3.6.conv2.weight
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_b     mapped name: layer3.6.conv3.bias
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_b  mapped name: layer3.6.bn3.bias
2024-04-12 19:37:34,338 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_bn_s  mapped name: layer3.6.bn3.weight
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_6_branch2c_w     mapped name: layer3.6.conv3.weight
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_b     mapped name: layer3.7.conv1.bias
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_b  mapped name: layer3.7.bn1.bias
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_bn_s  mapped name: layer3.7.bn1.weight
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2a_w     mapped name: layer3.7.conv1.weight
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_b     mapped name: layer3.7.conv2.bias
2024-04-12 19:37:34,339 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_b  mapped name: layer3.7.bn2.bias
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_bn_s  mapped name: layer3.7.bn2.weight
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2b_w     mapped name: layer3.7.conv2.weight
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_b     mapped name: layer3.7.conv3.bias
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_b  mapped name: layer3.7.bn3.bias
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_bn_s  mapped name: layer3.7.bn3.weight
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_7_branch2c_w     mapped name: layer3.7.conv3.weight
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_b     mapped name: layer3.8.conv1.bias
2024-04-12 19:37:34,340 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_b  mapped name: layer3.8.bn1.bias
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_bn_s  mapped name: layer3.8.bn1.weight
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2a_w     mapped name: layer3.8.conv1.weight
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_b     mapped name: layer3.8.conv2.bias
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_b  mapped name: layer3.8.bn2.bias
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_bn_s  mapped name: layer3.8.bn2.weight
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2b_w     mapped name: layer3.8.conv2.weight
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_b     mapped name: layer3.8.conv3.bias
2024-04-12 19:37:34,341 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_b  mapped name: layer3.8.bn3.bias
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_bn_s  mapped name: layer3.8.bn3.weight
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_8_branch2c_w     mapped name: layer3.8.conv3.weight
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_b     mapped name: layer3.9.conv1.bias
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_b  mapped name: layer3.9.bn1.bias
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_bn_s  mapped name: layer3.9.bn1.weight
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2a_w     mapped name: layer3.9.conv1.weight
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_b     mapped name: layer3.9.conv2.bias
2024-04-12 19:37:34,342 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_b  mapped name: layer3.9.bn2.bias
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_bn_s  mapped name: layer3.9.bn2.weight
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2b_w     mapped name: layer3.9.conv2.weight
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_b     mapped name: layer3.9.conv3.bias
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_b  mapped name: layer3.9.bn3.bias
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_bn_s  mapped name: layer3.9.bn3.weight
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res4_9_branch2c_w     mapped name: layer3.9.conv3.weight
2024-04-12 19:37:34,343 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_b      mapped name: layer4.0.downsample.0.bias
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_b   mapped name: layer4.0.downsample.1.bias
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_bn_s   mapped name: layer4.0.downsample.1.weight
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch1_w      mapped name: layer4.0.downsample.0.weight
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_b     mapped name: layer4.0.conv1.bias
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_b  mapped name: layer4.0.bn1.bias
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_bn_s  mapped name: layer4.0.bn1.weight
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2a_w     mapped name: layer4.0.conv1.weight
2024-04-12 19:37:34,344 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_b     mapped name: layer4.0.conv2.bias
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_b  mapped name: layer4.0.bn2.bias
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_bn_s  mapped name: layer4.0.bn2.weight
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2b_w     mapped name: layer4.0.conv2.weight
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_b     mapped name: layer4.0.conv3.bias
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_b  mapped name: layer4.0.bn3.bias
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_bn_s  mapped name: layer4.0.bn3.weight
2024-04-12 19:37:34,345 mega_core.utils.c2_model_loading INFO: C2 name: res5_0_branch2c_w     mapped name: layer4.0.conv3.weight
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_b     mapped name: layer4.1.conv1.bias
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_b  mapped name: layer4.1.bn1.bias
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_bn_s  mapped name: layer4.1.bn1.weight
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2a_w     mapped name: layer4.1.conv1.weight
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_b     mapped name: layer4.1.conv2.bias
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_b  mapped name: layer4.1.bn2.bias
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_bn_s  mapped name: layer4.1.bn2.weight
2024-04-12 19:37:34,346 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2b_w     mapped name: layer4.1.conv2.weight
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_b     mapped name: layer4.1.conv3.bias
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_b  mapped name: layer4.1.bn3.bias
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_bn_s  mapped name: layer4.1.bn3.weight
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_1_branch2c_w     mapped name: layer4.1.conv3.weight
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_b     mapped name: layer4.2.conv1.bias
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_b  mapped name: layer4.2.bn1.bias
2024-04-12 19:37:34,347 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_bn_s  mapped name: layer4.2.bn1.weight
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2a_w     mapped name: layer4.2.conv1.weight
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_b     mapped name: layer4.2.conv2.bias
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_b  mapped name: layer4.2.bn2.bias
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_bn_s  mapped name: layer4.2.bn2.weight
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2b_w     mapped name: layer4.2.conv2.weight
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_b     mapped name: layer4.2.conv3.bias
2024-04-12 19:37:34,348 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_b  mapped name: layer4.2.bn3.bias
2024-04-12 19:37:34,349 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_bn_s  mapped name: layer4.2.bn3.weight
2024-04-12 19:37:34,349 mega_core.utils.c2_model_loading INFO: C2 name: res5_2_branch2c_w     mapped name: layer4.2.conv3.weight
2024-04-12 19:37:34,349 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_b        mapped name: bn1.bias
2024-04-12 19:37:34,349 mega_core.utils.c2_model_loading INFO: C2 name: res_conv1_bn_s        mapped name: bn1.weight
2024-04-12 19:37:34,349 mega_core.utils.c2_model_loading INFO: Remapping conv weights for deformable conv weights
2024-04-12 19:37:36,111 mega_core.utils.miscellaneous INFO: Saving labels mapping into training_dir/test/labels.json
2024-04-12 19:37:36,896 mega_core.trainer INFO: Start training
2024-04-12 19:37:57,288 mega_core.trainer INFO: eta: 13:52:06  iter: 21  loss: 117.7138 (106.6542)  loss_classifier: 68.3576 (67.6955)  loss_box_reg: 4.6603 (6.1577)  loss_objectness: 4.1812 (5.6620)  loss_rpn_box_reg: 21.9304 (27.1391)  time: 0.9452 (1.0193)  data: 0.0169 (0.0905)  lr: 0.000003  max mem: 5764
2024-04-12 19:38:16,224 mega_core.trainer INFO: eta: 13:22:12  iter: 41  loss: 97.9186 (109.9649)  loss_classifier: 51.9418 (73.4748)  loss_box_reg: 7.2749 (8.0194)  loss_objectness: 3.5462 (5.2202)  loss_rpn_box_reg: 16.0774 (23.2505)  time: 0.9476 (0.9831)  data: 0.0153 (0.0533)  lr: 0.000003  max mem: 5764
2024-04-12 19:38:16,227 mega_core.inference INFO: Start evaluation on [Validation] dataset(4212 images).
2024-04-12 19:38:44,065 mega_core.inference INFO: Total run time: 0:00:27.837457 (0.006609082844635473 s / img per device, on 1 devices)
2024-04-12 19:38:44,066 mega_core.inference INFO: Model inference time: 0:00:09.060083 (0.002151016835813169 s / img per device, on 1 devices)
2024-04-12 19:38:56,517 mega_core.inference INFO: performing vid evaluation, ignored iou_types.
2024-04-12 19:38:59,616 mega_core.inference INFO: Preparing results for COCO format
2024-04-12 19:38:59,616 mega_core.inference INFO: Preparing bbox results
2024-04-12 19:38:59,617 mega_core.inference INFO: Evaluating predictions
2024-04-12 19:39:07,054 mega_core.inference INFO: 
Task: bbox
AP, AP50, AP75, APs, APm, APl
0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000

2024-04-12 19:39:07,145 mega_core.inference INFO: 
AP50 | motion=   all = 0.0000
Category AP:
carcrowd        : nan
bicycle         : 0.0000
bicyclecrowd    : nan
car             : 0.0000
ignore          : nan
people          : 0.0000
Mean CorLoc: 0.0000
Category CorLoc:
people          : 0.0000
bicycle         : 0.0000
car             : 0.0000

