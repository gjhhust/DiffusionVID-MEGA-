MODEL:
  VID:
    METHOD: "dafa"
    ROI_BOX_HEAD:
      ATTENTION:
        ENABLE: True  # local attention
        STAGE: 0  # local attention stages
    MEGA:
      MIN_OFFSET: -0
      MAX_OFFSET: 0
      ALL_FRAME_INTERVAL: 1
      KEY_FRAME_LOCATION: 0
      SHUFFLED_CUR_TEST : False
      LOCAL:
        ENABLE: False  # local frame access on training phase
        PIXEL_ATTEND: False
      MEMORY:
        ENABLE: False  # long range memory
      GLOBAL:
        ENABLE: True  # global attention & memory
        RES_STAGE: 2
        SIZE: 25  # global ref frames in initialization
        STOP_UPDATE_AFTER_INIT_TEST: True
        BOX_ATTEND: True
        PIXEL_ATTEND: False
        PIXEL_STAGE: 0
      MHA: False
      REF_NUM_GLOBAL: 4  # global ref frames in training
      MEMORY_MANAGEMENT_SIZE_TEST: 900
      MEMORY_MANAGEMENT_SIZE_TRAIN: 300
      MEMORY_MANAGEMENT_METRIC: "distance"  # mamba, queue, distance
      MEMORY_MANAGEMENT_TYPE: "greedy"  # once, twice, sequential, greedy, random
  META_ARCHITECTURE: "GeneralizedRCNNMEGA"
  WEIGHT: "catalog://ImageNetPretrained/MSRA/R-101"
  BACKBONE:
    CONV_BODY: "R-101-C4"
  ROI_BOX_HEAD:
    FEATURE_EXTRACTOR: "MEGAFeatureExtractor"
    PREDICTOR: "FPNPredictor"
DATASETS:
  TRAIN: ("DET_train_30classes", "VID_train_15frames")
  TEST: ("VID_val_videos",) # ("VID_val_videos",) # ("YouTube_Objects",)